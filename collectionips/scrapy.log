2017-11-27 10:33:01 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: collectionips)
2017-11-27 10:33:01 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'collectionips', 'DEPTH_LIMIT': 2, 'DOWNLOAD_DELAY': 10, 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'collectionips.spiders', 'SPIDER_MODULES': ['collectionips.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0'}
2017-11-27 10:33:01 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-27 10:33:02 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-27 10:33:03 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-27 10:33:03 [py.warnings] WARNING: E:\scrapy_study\collectionips\collectionips\pipelines.py:11: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-27 10:33:03 [scrapy.middleware] INFO: Enabled item pipelines:
['collectionips.pipelines.CollectionipsPipeline',
 'collectionips.pipelines.MySQLPipeline']
2017-11-27 10:33:03 [scrapy.core.engine] INFO: Spider opened
2017-11-27 10:33:03 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-27 10:33:03 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-11-27 10:33:04 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn> (referer: None)
2017-11-27 10:33:06 [py.warnings] WARNING: E:\scrapy_study\collectionips\collectionips\pipelines.py:31: ScrapyDeprecationWarning: log.err has been deprecated, create a python logger and use its error method instead
  log.err(e)

2017-11-27 10:33:06 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江杭州',
 'alive_time': '102天',
 'ip': '101.68.73.54',
 'port': '53281',
 'proof_time': '17-11-27 10:30',
 'speed': '0.218秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '101.68.73.54'',''53281'',''浙江杭州'',''HTTP'',''0.218秒'',''102天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:06 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xicidaili.com/nn/2> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '656天',
 'ip': '110.73.55.126',
 'port': '8123',
 'proof_time': '17-11-27 10:30',
 'speed': '0.3秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.55.126'',''8123'',''广西南宁'',''HTTP'',''0.3秒'',''656天'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '27天',
 'ip': '111.155.116.218',
 'port': '8123',
 'proof_time': '17-11-27 10:30',
 'speed': '1.063秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '111.155.116.218'',''8123'',''北京'',''HTTP'',''1.063秒'',''27天'',''17-11-27' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '辽宁大连',
 'alive_time': '8小时',
 'ip': '113.226.146.239',
 'port': '8080',
 'proof_time': '17-11-27 10:26',
 'speed': '0.104秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '113.226.146.239'',''8080'',''辽宁大连'',''HTTP'',''0.104秒'',''8小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '辽宁葫芦岛',
 'alive_time': '3天',
 'ip': '123.56.86.187',
 'port': '3128',
 'proof_time': '17-11-27 10:26',
 'speed': '0.01秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.56.86.187'',''3128'',''辽宁葫芦岛'',''HTTPS'',''0.01秒'',''3天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '10小时',
 'ip': '219.138.58.187',
 'port': '3128',
 'proof_time': '17-11-27 10:25',
 'speed': '0.834秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.187'',''3128'',''湖北襄阳'',''HTTP'',''0.834秒'',''10小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南郑州',
 'alive_time': '8小时',
 'ip': '122.114.31.177',
 'port': '808',
 'proof_time': '17-11-27 10:24',
 'speed': '0.107秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.114.31.177'',''808'',''河南郑州'',''HTTP'',''0.107秒'',''8小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '563天',
 'ip': '61.135.217.7',
 'port': '80',
 'proof_time': '17-11-27 10:24',
 'speed': '0.324秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '61.135.217.7'',''80'',''北京'',''HTTP'',''0.324秒'',''563天'',''17-11-27 10:' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '',
 'alive_time': '1天',
 'ip': '123.207.8.94',
 'port': '8080',
 'proof_time': '17-11-27 10:24',
 'speed': '0.178秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.207.8.94'',''8080'','''',''HTTPS'',''0.178秒'',''1天'',''17-11-27 10:24'')' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '2小时',
 'ip': '115.217.25.246',
 'port': '808',
 'proof_time': '17-11-27 10:23',
 'speed': '2.345秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.217.25.246'',''808'',''浙江宁波'',''HTTP'',''2.345秒'',''2小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '6小时',
 'ip': '221.233.85.141',
 'port': '3128',
 'proof_time': '17-11-27 10:22',
 'speed': '0.929秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '221.233.85.141'',''3128'',''湖北襄阳'',''HTTPS'',''0.929秒'',''6小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '118天',
 'ip': '112.114.95.56',
 'port': '8118',
 'proof_time': '17-11-27 10:22',
 'speed': '0.328秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.95.56'',''8118'',''云南临沧'',''HTTPS'',''0.328秒'',''118天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '114天',
 'ip': '112.114.96.164',
 'port': '8118',
 'proof_time': '17-11-27 10:18',
 'speed': '0.909秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.96.164'',''8118'',''云南临沧'',''HTTPS'',''0.909秒'',''114天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:07 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏扬州',
 'alive_time': '1分钟',
 'ip': '114.230.127.127',
 'port': '23294',
 'proof_time': '17-11-27 10:16',
 'speed': '3.887秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.230.127.127'',''23294'',''江苏扬州'',''HTTP'',''3.887秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.25.87',
 'port': '8123',
 'proof_time': '17-11-27 10:16',
 'speed': '4.339秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.25.87'',''8123'',''广西贵港'',''HTTP'',''4.339秒'',''1分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.20.6',
 'port': '8123',
 'proof_time': '17-11-27 10:15',
 'speed': '5.925秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.20.6'',''8123'',''广西贵港'',''HTTP'',''5.925秒'',''1分钟'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '铁通',
 'alive_time': '1天',
 'ip': '110.216.60.136',
 'port': '80',
 'proof_time': '17-11-27 10:11',
 'speed': '0.347秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.216.60.136'',''80'',''铁通'',''HTTP'',''0.347秒'',''1天'',''17-11-27 10:' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河北保定',
 'alive_time': '1分钟',
 'ip': '124.237.128.42',
 'port': '9999',
 'proof_time': '17-11-27 10:11',
 'speed': '0.154秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '124.237.128.42'',''9999'',''河北保定'',''HTTPS'',''0.154秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '182.88.187.217',
 'port': '8123',
 'proof_time': '17-11-27 10:11',
 'speed': '0.483秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.88.187.217'',''8123'',''广西南宁'',''HTTPS'',''0.483秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.20',
 'port': '8010',
 'proof_time': '17-11-27 10:11',
 'speed': '6.217秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.79.20'',''8010'',''安徽芜湖'',''HTTPS'',''6.217秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '86天',
 'ip': '110.72.17.204',
 'port': '8123',
 'proof_time': '17-11-27 10:11',
 'speed': '3.55秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.17.204'',''8123'',''广西贵港'',''HTTP'',''3.55秒'',''86天'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '上海',
 'alive_time': '10小时',
 'ip': '180.175.120.96',
 'port': '51552',
 'proof_time': '17-11-27 10:10',
 'speed': '0.191秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.175.120.96'',''51552'',''上海'',''HTTPS'',''0.191秒'',''10小时'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山西大同',
 'alive_time': '7小时',
 'ip': '118.72.124.97',
 'port': '80',
 'proof_time': '17-11-27 10:09',
 'speed': '0.098秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '118.72.124.97'',''80'',''山西大同'',''HTTPS'',''0.098秒'',''7小时'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南三门峡',
 'alive_time': '21小时',
 'ip': '123.55.190.127',
 'port': '30670',
 'proof_time': '17-11-27 10:04',
 'speed': '0.265秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.55.190.127'',''30670'',''河南三门峡'',''HTTPS'',''0.265秒'',''21小时' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建泉州',
 'alive_time': '13小时',
 'ip': '117.24.36.67',
 'port': '808',
 'proof_time': '17-11-27 10:03',
 'speed': '3.546秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '117.24.36.67'',''808'',''福建泉州'',''HTTPS'',''3.546秒'',''13小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建龙岩',
 'alive_time': '1分钟',
 'ip': '121.206.87.230',
 'port': '46046',
 'proof_time': '17-11-27 09:55',
 'speed': '0.24秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.206.87.230'',''46046'',''福建龙岩'',''HTTPS'',''0.24秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江杭州',
 'alive_time': '3天',
 'ip': '125.119.160.69',
 'port': '8118',
 'proof_time': '17-11-27 09:47',
 'speed': '2.334秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '125.119.160.69'',''8118'',''浙江杭州'',''HTTP'',''2.334秒'',''3天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏镇江',
 'alive_time': '2分钟',
 'ip': '180.118.195.69',
 'port': '23959',
 'proof_time': '17-11-27 09:46',
 'speed': '0.54秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.118.195.69'',''23959'',''江苏镇江'',''HTTPS'',''0.54秒'',''2分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '5天',
 'ip': '219.138.58.59',
 'port': '3128',
 'proof_time': '17-11-27 09:45',
 'speed': '1.237秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.59'',''3128'',''湖北襄阳'',''HTTPS'',''1.237秒'',''5天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东东莞',
 'alive_time': '1小时',
 'ip': '113.79.74.68',
 'port': '808',
 'proof_time': '17-11-27 09:42',
 'speed': '0.224秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '113.79.74.68'',''808'',''广东东莞'',''HTTPS'',''0.224秒'',''1小时'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '484天',
 'ip': '110.72.22.61',
 'port': '8123',
 'proof_time': '17-11-27 09:41',
 'speed': '0.575秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.22.61'',''8123'',''广西贵港'',''HTTP'',''0.575秒'',''484天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '31天',
 'ip': '120.25.164.134',
 'port': '8118',
 'proof_time': '17-11-27 09:34',
 'speed': '0.239秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '120.25.164.134'',''8118'',''北京'',''HTTP'',''0.239秒'',''31天'',''17-11-27 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '230天',
 'ip': '111.155.116.215',
 'port': '8123',
 'proof_time': '17-11-27 09:22',
 'speed': '1.808秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '111.155.116.215'',''8123'',''北京'',''HTTP'',''1.808秒'',''230天'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '119天',
 'ip': '111.155.116.232',
 'port': '8123',
 'proof_time': '17-11-27 09:21',
 'speed': '2.736秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '111.155.116.232'',''8123'',''北京'',''HTTPS'',''2.736秒'',''119天'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '100天',
 'ip': '112.114.95.59',
 'port': '8118',
 'proof_time': '17-11-27 09:19',
 'speed': '0.363秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.95.59'',''8118'',''云南临沧'',''HTTPS'',''0.363秒'',''100天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '12小时',
 'ip': '219.138.58.33',
 'port': '3128',
 'proof_time': '17-11-27 09:14',
 'speed': '0.693秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.33'',''3128'',''湖北襄阳'',''HTTP'',''0.693秒'',''12小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江绍兴',
 'alive_time': '7小时',
 'ip': '183.144.192.184',
 'port': '3128',
 'proof_time': '17-11-27 09:12',
 'speed': '0.417秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '183.144.192.184'',''3128'',''浙江绍兴'',''HTTP'',''0.417秒'',''7小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '四川泸州',
 'alive_time': '13天',
 'ip': '218.88.215.109',
 'port': '8118',
 'proof_time': '17-11-27 09:10',
 'speed': '0.263秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '218.88.215.109'',''8118'',''四川泸州'',''HTTPS'',''0.263秒'',''13天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江西',
 'alive_time': '7天',
 'ip': '171.35.103.37',
 'port': '808',
 'proof_time': '17-11-27 09:09',
 'speed': '0.196秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.35.103.37'',''808'',''江西'',''HTTPS'',''0.196秒'',''7天'',''17-11-27 09' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.99.227',
 'port': '8118',
 'proof_time': '17-11-27 09:01',
 'speed': '0.343秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.99.227'',''8118'',''云南临沧'',''HTTPS'',''0.343秒'',''1小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东日照',
 'alive_time': '5小时',
 'ip': '182.37.117.26',
 'port': '808',
 'proof_time': '17-11-27 08:53',
 'speed': '0.169秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.37.117.26'',''808'',''山东日照'',''HTTPS'',''0.169秒'',''5小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '上海',
 'alive_time': '2天',
 'ip': '58.246.123.42',
 'port': '808',
 'proof_time': '17-11-27 08:53',
 'speed': '0.144秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '58.246.123.42'',''808'',''上海'',''HTTPS'',''0.144秒'',''2天'',''17-11-27 08' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.97.127',
 'port': '8118',
 'proof_time': '17-11-27 08:51',
 'speed': '0.32秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.97.127'',''8118'',''云南临沧'',''HTTPS'',''0.32秒'',''1小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.252.150',
 'port': '29745',
 'proof_time': '17-11-27 08:46',
 'speed': '0.171秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.217.252.150'',''29745'',''浙江宁波'',''HTTPS'',''0.171秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '22小时',
 'ip': '223.241.119.208',
 'port': '8010',
 'proof_time': '17-11-27 08:46',
 'speed': '7.188秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.208'',''8010'',''安徽'',''HTTP'',''7.188秒'',''22小时'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东济南',
 'alive_time': '2分钟',
 'ip': '122.4.43.19',
 'port': '42331',
 'proof_time': '17-11-27 08:46',
 'speed': '0.132秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.4.43.19'',''42331'',''山东济南'',''HTTPS'',''0.132秒'',''2分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江丽水',
 'alive_time': '2分钟',
 'ip': '115.213.206.220',
 'port': '33904',
 'proof_time': '17-11-27 08:46',
 'speed': '1.251秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.213.206.220'',''33904'',''浙江丽水'',''HTTPS'',''1.251秒'',''2分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江',
 'alive_time': '1分钟',
 'ip': '36.25.111.118',
 'port': '40064',
 'proof_time': '17-11-27 08:45',
 'speed': '0.144秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '36.25.111.118'',''40064'',''浙江'',''HTTPS'',''0.144秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '483天',
 'ip': '182.88.44.116',
 'port': '8123',
 'proof_time': '17-11-27 08:45',
 'speed': '7.174秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.88.44.116'',''8123'',''广西南宁'',''HTTP'',''7.174秒'',''483天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '7天',
 'ip': '223.241.79.224',
 'port': '8010',
 'proof_time': '17-11-27 08:44',
 'speed': '2.11秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.79.224'',''8010'',''安徽芜湖'',''HTTP'',''2.11秒'',''7天'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.243',
 'port': '8010',
 'proof_time': '17-11-27 08:44',
 'speed': '2.548秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.243'',''8010'',''安徽芜湖'',''HTTPS'',''2.548秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '黑龙江哈尔滨',
 'alive_time': '100天',
 'ip': '125.211.202.26',
 'port': '53281',
 'proof_time': '17-11-27 08:39',
 'speed': '2.836秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '125.211.202.26'',''53281'',''黑龙江哈尔滨'',''HTTP'',''2.836秒'',''100天' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建福州',
 'alive_time': '7分钟',
 'ip': '27.156.215.117',
 'port': '39382',
 'proof_time': '17-11-27 08:30',
 'speed': '0.197秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '27.156.215.117'',''39382'',''福建福州'',''HTTPS'',''0.197秒'',''7分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1小时',
 'ip': '110.72.17.11',
 'port': '8123',
 'proof_time': '17-11-27 08:30',
 'speed': '2.125秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.17.11'',''8123'',''广西贵港'',''HTTPS'',''2.125秒'',''1小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏南通',
 'alive_time': '1分钟',
 'ip': '117.86.204.52',
 'port': '28488',
 'proof_time': '17-11-27 08:22',
 'speed': '0.147秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '117.86.204.52'',''28488'',''江苏南通'',''HTTPS'',''0.147秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '29天',
 'ip': '223.241.78.85',
 'port': '8010',
 'proof_time': '17-11-27 08:22',
 'speed': '1.931秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.85'',''8010'',''安徽芜湖'',''HTTPS'',''1.931秒'',''29天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江舟山',
 'alive_time': '6分钟',
 'ip': '123.96.0.101',
 'port': '33042',
 'proof_time': '17-11-27 08:22',
 'speed': '0.26秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.96.0.101'',''33042'',''浙江舟山'',''HTTP'',''0.26秒'',''6分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:08 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西玉林',
 'alive_time': '713天',
 'ip': '171.38.85.125',
 'port': '8123',
 'proof_time': '17-11-27 08:22',
 'speed': '1.077秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.38.85.125'',''8123'',''广西玉林'',''HTTP'',''1.077秒'',''713天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏南通',
 'alive_time': '6分钟',
 'ip': '117.86.166.92',
 'port': '20638',
 'proof_time': '17-11-27 08:21',
 'speed': '0.173秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '117.86.166.92'',''20638'',''江苏南通'',''HTTP'',''0.173秒'',''6分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏泰州',
 'alive_time': '1分钟',
 'ip': '180.122.149.206',
 'port': '24295',
 'proof_time': '17-11-27 08:15',
 'speed': '0.153秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.122.149.206'',''24295'',''江苏泰州'',''HTTP'',''0.153秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '218.81.237.58',
 'port': '22624',
 'proof_time': '17-11-27 08:15',
 'speed': '0.127秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '218.81.237.58'',''22624'',''上海'',''HTTP'',''0.127秒'',''1分钟'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东茂名',
 'alive_time': '6小时',
 'ip': '113.94.76.14',
 'port': '3128',
 'proof_time': '17-11-27 08:11',
 'speed': '0.2秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '113.94.76.14'',''3128'',''广东茂名'',''HTTP'',''0.2秒'',''6小时'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '1小时',
 'ip': '221.233.85.110',
 'port': '3128',
 'proof_time': '17-11-27 08:09',
 'speed': '0.71秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '221.233.85.110'',''3128'',''湖北襄阳'',''HTTPS'',''0.71秒'',''1小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '19分钟',
 'ip': '219.138.58.202',
 'port': '3128',
 'proof_time': '17-11-27 08:04',
 'speed': '0.782秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.202'',''3128'',''湖北襄阳'',''HTTP'',''0.782秒'',''19分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '四川成都',
 'alive_time': '674天',
 'ip': '118.114.77.47',
 'port': '8080',
 'proof_time': '17-11-27 08:01',
 'speed': '3.136秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '118.114.77.47'',''8080'',''四川成都'',''HTTP'',''3.136秒'',''674天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '17天',
 'ip': '223.241.116.220',
 'port': '8010',
 'proof_time': '17-11-27 07:55',
 'speed': '5.715秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.220'',''8010'',''安徽'',''HTTPS'',''5.715秒'',''17天'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '11小时',
 'ip': '223.241.118.214',
 'port': '8010',
 'proof_time': '17-11-27 07:55',
 'speed': '6.703秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.118.214'',''8010'',''安徽'',''HTTPS'',''6.703秒'',''11小时'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.76.5',
 'port': '8123',
 'proof_time': '17-11-27 07:45',
 'speed': '4.871秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.76.5'',''8123'',''广西南宁'',''HTTPS'',''4.871秒'',''1分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建厦门',
 'alive_time': '357天',
 'ip': '121.204.165.246',
 'port': '8118',
 'proof_time': '17-11-27 07:40',
 'speed': '0.179秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.204.165.246'',''8118'',''福建厦门'',''HTTP'',''0.179秒'',''357天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '98天',
 'ip': '118.187.58.34',
 'port': '53281',
 'proof_time': '17-11-27 07:35',
 'speed': '1.137秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '118.187.58.34'',''53281'',''北京'',''HTTP'',''1.137秒'',''98天'',''17-11-27 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.99.147',
 'port': '8123',
 'proof_time': '17-11-27 07:31',
 'speed': '5.513秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.99.147'',''8123'',''广西南宁'',''HTTP'',''5.513秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.120.40',
 'port': '8123',
 'proof_time': '17-11-27 07:31',
 'speed': '0.328秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.120.40'',''8123'',''广西梧州'',''HTTP'',''0.328秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏',
 'alive_time': '1分钟',
 'ip': '117.62.177.126',
 'port': '8118',
 'proof_time': '17-11-27 07:22',
 'speed': '4.886秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '117.62.177.126'',''8118'',''江苏'',''HTTPS'',''4.886秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '34天',
 'ip': '223.241.79.7',
 'port': '8010',
 'proof_time': '17-11-27 07:22',
 'speed': '5.675秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.79.7'',''8010'',''安徽芜湖'',''HTTPS'',''5.675秒'',''34天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '5小时',
 'ip': '221.233.85.235',
 'port': '3128',
 'proof_time': '17-11-27 07:22',
 'speed': '1.231秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '221.233.85.235'',''3128'',''湖北襄阳'',''HTTPS'',''1.231秒'',''5小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江台州',
 'alive_time': '10小时',
 'ip': '115.203.221.178',
 'port': '8888',
 'proof_time': '17-11-27 07:21',
 'speed': '0.859秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.203.221.178'',''8888'',''浙江台州'',''HTTP'',''0.859秒'',''10小时'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1119天',
 'ip': '60.169.78.218',
 'port': '808',
 'proof_time': '17-11-27 07:21',
 'speed': '2.68秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '60.169.78.218'',''808'',''安徽芜湖'',''HTTP'',''2.68秒'',''1119天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏无锡',
 'alive_time': '1分钟',
 'ip': '114.224.85.225',
 'port': '38954',
 'proof_time': '17-11-27 06:55',
 'speed': '1.259秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.224.85.225'',''38954'',''江苏无锡'',''HTTPS'',''1.259秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '222.79.178.83',
 'port': '45956',
 'proof_time': '17-11-27 06:55',
 'speed': '0.184秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '222.79.178.83'',''45956'',''福建泉州'',''HTTPS'',''0.184秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江丽水',
 'alive_time': '1分钟',
 'ip': '115.230.79.93',
 'port': '46297',
 'proof_time': '17-11-27 06:55',
 'speed': '1.76秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.230.79.93'',''46297'',''浙江丽水'',''HTTPS'',''1.76秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建福州',
 'alive_time': '1分钟',
 'ip': '27.156.195.189',
 'port': '40298',
 'proof_time': '17-11-27 06:55',
 'speed': '1.659秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '27.156.195.189'',''40298'',''福建福州'',''HTTPS'',''1.659秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '433天',
 'ip': '202.108.2.42',
 'port': '80',
 'proof_time': '17-11-27 06:39',
 'speed': '5.855秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '202.108.2.42'',''80'',''北京'',''HTTP'',''5.855秒'',''433天'',''17-11-27 06:' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江杭州',
 'alive_time': '229天',
 'ip': '125.120.40.65',
 'port': '808',
 'proof_time': '17-11-27 06:33',
 'speed': '4.099秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '125.120.40.65'',''808'',''浙江杭州'',''HTTPS'',''4.099秒'',''229天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.119.63',
 'port': '8010',
 'proof_time': '17-11-27 06:31',
 'speed': '7.536秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.63'',''8010'',''安徽'',''HTTP'',''7.536秒'',''7天'',''17-11-27 0' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.91',
 'port': '8010',
 'proof_time': '17-11-27 06:22',
 'speed': '2.714秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.79.91'',''8010'',''安徽芜湖'',''HTTPS'',''2.714秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '吉林四平',
 'alive_time': '4小时',
 'ip': '122.143.142.25',
 'port': '80',
 'proof_time': '17-11-27 06:17',
 'speed': '0.103秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.143.142.25'',''80'',''吉林四平'',''HTTP'',''0.103秒'',''4小时'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.122',
 'port': '8010',
 'proof_time': '17-11-27 06:15',
 'speed': '1.954秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.122'',''8010'',''安徽芜湖'',''HTTP'',''1.954秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '5天',
 'ip': '223.241.119.198',
 'port': '8010',
 'proof_time': '17-11-27 06:01',
 'speed': '0.52秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.198'',''8010'',''安徽'',''HTTPS'',''0.52秒'',''5天'',''17-11-27 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '60天',
 'ip': '223.241.116.35',
 'port': '8010',
 'proof_time': '17-11-27 05:55',
 'speed': '5.749秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.35'',''8010'',''安徽'',''HTTPS'',''5.749秒'',''60天'',''17-11-27' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '36.7.58.8',
 'port': '49151',
 'proof_time': '17-11-27 05:44',
 'speed': '5.252秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '36.7.58.8'',''49151'',''安徽'',''HTTPS'',''5.252秒'',''1分钟'',''17-11-27 0' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '121.205.11.189',
 'port': '29970',
 'proof_time': '17-11-27 05:44',
 'speed': '0.183秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.205.11.189'',''29970'',''福建泉州'',''HTTPS'',''0.183秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江嘉兴',
 'alive_time': '3分钟',
 'ip': '122.231.32.27',
 'port': '24567',
 'proof_time': '17-11-27 05:33',
 'speed': '0.605秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.231.32.27'',''24567'',''浙江嘉兴'',''HTTP'',''0.605秒'',''3分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '114.228.75.179',
 'port': '53650',
 'proof_time': '17-11-27 05:30',
 'speed': '1.897秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.228.75.179'',''53650'',''江苏常州'',''HTTP'',''1.897秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东广州',
 'alive_time': '101天',
 'ip': '183.63.140.82',
 'port': '53281',
 'proof_time': '17-11-27 05:22',
 'speed': '0.258秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '183.63.140.82'',''53281'',''广东广州'',''HTTPS'',''0.258秒'',''101天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南平顶山',
 'alive_time': '1分钟',
 'ip': '123.161.237.255',
 'port': '47565',
 'proof_time': '17-11-27 05:22',
 'speed': '0.13秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.161.237.255'',''47565'',''河南平顶山'',''HTTPS'',''0.13秒'',''1分钟'' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.215.51.161',
 'port': '42517',
 'proof_time': '17-11-27 05:22',
 'speed': '0.175秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.215.51.161'',''42517'',''浙江宁波'',''HTTPS'',''0.175秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏常州',
 'alive_time': '6分钟',
 'ip': '218.93.105.98',
 'port': '40260',
 'proof_time': '17-11-27 05:21',
 'speed': '6.653秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '218.93.105.98'',''40260'',''江苏常州'',''HTTP'',''6.653秒'',''6分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '天津',
 'alive_time': '1分钟',
 'ip': '180.213.173.19',
 'port': '8123',
 'proof_time': '17-11-27 05:11',
 'speed': '5.964秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.213.173.19'',''8123'',''天津'',''HTTPS'',''5.964秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.223',
 'port': '8010',
 'proof_time': '17-11-27 05:11',
 'speed': '2.156秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.223'',''8010'',''安徽芜湖'',''HTTPS'',''2.156秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:09 [scrapy.core.scraper] ERROR: Error processing {'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.177.143.109',
 'port': '49715',
 'proof_time': '17-11-27 04:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '42.177.143.109'',''49715'',''辽宁'',''HTTPS'',''0.509秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/2> (referer: http://www.xicidaili.com/nn)
2017-11-27 10:33:15 [scrapy.core.scraper] ERROR: Error processing {'addrs': '甘肃兰州市城关区',
 'alive_time': '633天',
 'ip': '61.178.238.122',
 'port': '63000',
 'proof_time': '17-11-27 04:41',
 'speed': '0.338秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '61.178.238.122'',''63000'',''甘肃兰州市城关区'',''HTTP'',''0.338秒'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:15 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '18天',
 'ip': '223.241.118.61',
 'port': '8010',
 'proof_time': '17-11-27 04:31',
 'speed': '2.004秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.118.61'',''8010'',''安徽'',''HTTPS'',''2.004秒'',''18天'',''17-11-27' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:15 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.121',
 'port': '8010',
 'proof_time': '17-11-27 04:31',
 'speed': '0.565秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.121'',''8010'',''安徽'',''HTTP'',''0.565秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.19',
 'port': '8010',
 'proof_time': '17-11-27 04:11',
 'speed': '7.059秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.19'',''8010'',''安徽芜湖'',''HTTPS'',''7.059秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.93',
 'port': '8010',
 'proof_time': '17-11-27 04:11',
 'speed': '3.515秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.118.93'',''8010'',''安徽'',''HTTPS'',''3.515秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.67.22',
 'port': '8123',
 'proof_time': '17-11-27 03:55',
 'speed': '3.294秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.67.22'',''8123'',''广西南宁'',''HTTPS'',''3.294秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '125.112.195.191',
 'port': '46118',
 'proof_time': '17-11-27 03:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '125.112.195.191'',''46118'',''浙江金华'',''HTTPS'',''0.509秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南平顶山',
 'alive_time': '214天',
 'ip': '222.85.39.20',
 'port': '808',
 'proof_time': '17-11-27 03:55',
 'speed': '1.005秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '222.85.39.20'',''808'',''河南平顶山'',''HTTPS'',''1.005秒'',''214天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '222.71.89.136',
 'port': '46443',
 'proof_time': '17-11-27 03:55',
 'speed': '0.126秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '222.71.89.136'',''46443'',''上海'',''HTTPS'',''0.126秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '黑龙江',
 'alive_time': '1分钟',
 'ip': '116.62.217.206',
 'port': '80',
 'proof_time': '17-11-27 03:46',
 'speed': '2.201秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '116.62.217.206'',''80'',''黑龙江'',''HTTP'',''2.201秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.254.247',
 'port': '39426',
 'proof_time': '17-11-27 03:46',
 'speed': '0.162秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.217.254.247'',''39426'',''浙江宁波'',''HTTPS'',''0.162秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '',
 'alive_time': '2天',
 'ip': '106.42.97.33',
 'port': '808',
 'proof_time': '17-11-27 03:30',
 'speed': '3.181秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '106.42.97.33'',''808'','''',''HTTPS'',''3.181秒'',''2天'',''17-11-27 03:30'')' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '1天',
 'ip': '183.172.232.222',
 'port': '8118',
 'proof_time': '17-11-27 03:01',
 'speed': '0.145秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '183.172.232.222'',''8118'',''北京'',''HTTPS'',''0.145秒'',''1天'',''17-11-27' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河北保定',
 'alive_time': '1分钟',
 'ip': '124.237.128.148',
 'port': '9999',
 'proof_time': '17-11-27 03:00',
 'speed': '0.111秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '124.237.128.148'',''9999'',''河北保定'',''HTTPS'',''0.111秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.138.77',
 'port': '8123',
 'proof_time': '17-11-27 03:00',
 'speed': '4.072秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.138.77'',''8123'',''广西北海'',''HTTP'',''4.072秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏苏州',
 'alive_time': '1分钟',
 'ip': '222.93.241.22',
 'port': '25206',
 'proof_time': '17-11-27 02:46',
 'speed': '3.017秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '222.93.241.22'',''25206'',''江苏苏州'',''HTTPS'',''3.017秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.28.161',
 'port': '8123',
 'proof_time': '17-11-27 02:45',
 'speed': '3.304秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.28.161'',''8123'',''广西贵港'',''HTTP'',''3.304秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '114.234.82.2',
 'port': '36847',
 'proof_time': '17-11-27 02:45',
 'speed': '3.926秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.234.82.2'',''36847'',''江苏徐州'',''HTTPS'',''3.926秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '2分钟',
 'ip': '182.88.179.176',
 'port': '8123',
 'proof_time': '17-11-27 02:33',
 'speed': '4.206秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.88.179.176'',''8123'',''广西南宁'',''HTTP'',''4.206秒'',''2分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '陕西渭南',
 'alive_time': '105天',
 'ip': '124.89.33.59',
 'port': '53281',
 'proof_time': '17-11-27 02:31',
 'speed': '0.11秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '124.89.33.59'',''53281'',''陕西渭南'',''HTTPS'',''0.11秒'',''105天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东东莞',
 'alive_time': '3小时',
 'ip': '113.77.100.84',
 'port': '3128',
 'proof_time': '17-11-27 02:16',
 'speed': '0.471秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '113.77.100.84'',''3128'',''广东东莞'',''HTTP'',''0.471秒'',''3小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '125.109.197.191',
 'port': '29717',
 'proof_time': '17-11-27 02:16',
 'speed': '0.513秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '125.109.197.191'',''29717'',''浙江温州'',''HTTP'',''0.513秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '382天',
 'ip': '110.73.54.218',
 'port': '8123',
 'proof_time': '17-11-27 02:16',
 'speed': '4.395秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.54.218'',''8123'',''广西南宁'',''HTTP'',''4.395秒'',''382天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '708天',
 'ip': '121.31.79.243',
 'port': '8123',
 'proof_time': '17-11-27 02:16',
 'speed': '7.653秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.79.243'',''8123'',''广西梧州'',''HTTP'',''7.653秒'',''708天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '4分钟',
 'ip': '110.73.30.100',
 'port': '8123',
 'proof_time': '17-11-27 02:15',
 'speed': '2.91秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.30.100'',''8123'',''广西防城港'',''HTTPS'',''2.91秒'',''4分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.50.90',
 'port': '8123',
 'proof_time': '17-11-27 02:11',
 'speed': '1.482秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.50.90'',''8123'',''广西南宁'',''HTTPS'',''1.482秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '104天',
 'ip': '110.73.30.197',
 'port': '8123',
 'proof_time': '17-11-27 02:11',
 'speed': '3.901秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.30.197'',''8123'',''广西防城港'',''HTTPS'',''3.901秒'',''104天'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.79.182',
 'port': '8118',
 'proof_time': '17-11-27 02:09',
 'speed': '0.325秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.79.182'',''8118'',''云南临沧'',''HTTPS'',''0.325秒'',''1小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.71.165',
 'port': '8123',
 'proof_time': '17-11-27 02:01',
 'speed': '2.833秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.71.165'',''8123'',''广西梧州'',''HTTPS'',''2.833秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西',
 'alive_time': '1分钟',
 'ip': '171.37.171.1',
 'port': '8123',
 'proof_time': '17-11-27 02:00',
 'speed': '0.365秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.37.171.1'',''8123'',''广西'',''HTTPS'',''0.365秒'',''1分钟'',''17-11-27' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '552天',
 'ip': '182.90.69.230',
 'port': '8123',
 'proof_time': '17-11-27 01:56',
 'speed': '6.033秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.69.230'',''8123'',''广西梧州'',''HTTP'',''6.033秒'',''552天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西玉林',
 'alive_time': '1分钟',
 'ip': '171.38.42.238',
 'port': '8123',
 'proof_time': '17-11-27 01:55',
 'speed': '5.622秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.38.42.238'',''8123'',''广西玉林'',''HTTPS'',''5.622秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西玉林',
 'alive_time': '1分钟',
 'ip': '171.38.65.81',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.276秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.38.65.81'',''8123'',''广西玉林'',''HTTP'',''0.276秒'',''1分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '642天',
 'ip': '121.31.144.228',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.354秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.144.228'',''8123'',''广西北海'',''HTTP'',''0.354秒'',''642天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.27.175',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '3.756秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.27.175'',''8123'',''广西贵港'',''HTTP'',''3.756秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '548天',
 'ip': '110.73.55.185',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '4.399秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.55.185'',''8123'',''广西南宁'',''HTTP'',''4.399秒'',''548天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.79.125',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.262秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.79.125'',''8123'',''广西梧州'',''HTTP'',''0.262秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.54.115',
 'port': '8123',
 'proof_time': '17-11-27 01:44',
 'speed': '6.044秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.54.115'',''8123'',''广西南宁'',''HTTPS'',''6.044秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '136天',
 'ip': '61.135.155.82',
 'port': '443',
 'proof_time': '17-11-27 01:33',
 'speed': '3.462秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '61.135.155.82'',''443'',''北京'',''HTTP'',''3.462秒'',''136天'',''17-11-27 0' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.117.5',
 'port': '8010',
 'proof_time': '17-11-27 01:31',
 'speed': '0.79秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.117.5'',''8010'',''安徽'',''HTTP'',''0.79秒'',''1分钟'',''17-11-27 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '4分钟',
 'ip': '223.241.116.27',
 'port': '8010',
 'proof_time': '17-11-27 01:15',
 'speed': '2.437秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.27'',''8010'',''安徽'',''HTTPS'',''2.437秒'',''4分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '54天',
 'ip': '115.46.69.28',
 'port': '8123',
 'proof_time': '17-11-27 01:11',
 'speed': '5.763秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.69.28'',''8123'',''广西南宁'',''HTTP'',''5.763秒'',''54天'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '铁通',
 'alive_time': '46天',
 'ip': '114.115.216.99',
 'port': '80',
 'proof_time': '17-11-27 01:08',
 'speed': '0.045秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.115.216.99'',''80'',''铁通'',''HTTP'',''0.045秒'',''46天'',''17-11-27 01' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '19天',
 'ip': '223.241.116.88',
 'port': '8010',
 'proof_time': '17-11-27 00:55',
 'speed': '0.694秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.88'',''8010'',''安徽'',''HTTPS'',''0.694秒'',''19天'',''17-11-27' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '四川德阳',
 'alive_time': '1分钟',
 'ip': '110.189.207.224',
 'port': '37695',
 'proof_time': '17-11-27 00:55',
 'speed': '2.267秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.189.207.224'',''37695'',''四川德阳'',''HTTPS'',''2.267秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '60.169.216.165',
 'port': '44800',
 'proof_time': '17-11-27 00:55',
 'speed': '0.176秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '60.169.216.165'',''44800'',''安徽'',''HTTPS'',''0.176秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.219.222',
 'port': '32022',
 'proof_time': '17-11-27 00:55',
 'speed': '0.606秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.242.219.222'',''32022'',''浙江金华'',''HTTPS'',''0.606秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '114.234.82.127',
 'port': '33375',
 'proof_time': '17-11-27 00:44',
 'speed': '3.91秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.234.82.127'',''33375'',''江苏徐州'',''HTTPS'',''3.91秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.88.181',
 'port': '32473',
 'proof_time': '17-11-27 00:44',
 'speed': '5.954秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.242.88.181'',''32473'',''浙江金华'',''HTTPS'',''5.954秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东济南',
 'alive_time': '1分钟',
 'ip': '122.4.47.99',
 'port': '38981',
 'proof_time': '17-11-27 00:44',
 'speed': '4.461秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.4.47.99'',''38981'',''山东济南'',''HTTPS'',''4.461秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东枣庄',
 'alive_time': '774天',
 'ip': '60.214.118.170',
 'port': '63000',
 'proof_time': '17-11-27 00:42',
 'speed': '0.218秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '60.214.118.170'',''63000'',''山东枣庄'',''HTTP'',''0.218秒'',''774天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '吉林长春',
 'alive_time': '1小时',
 'ip': '123.173.81.190',
 'port': '80',
 'proof_time': '17-11-27 00:40',
 'speed': '1.406秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.173.81.190'',''80'',''吉林长春'',''HTTPS'',''1.406秒'',''1小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '吉林长春',
 'alive_time': '11小时',
 'ip': '58.244.59.208',
 'port': '8080',
 'proof_time': '17-11-27 00:31',
 'speed': '0.088秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '58.244.59.208'',''8080'',''吉林长春'',''HTTPS'',''0.088秒'',''11小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '上海',
 'alive_time': '14天',
 'ip': '116.231.35.5',
 'port': '8118',
 'proof_time': '17-11-27 00:23',
 'speed': '0.269秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '116.231.35.5'',''8118'',''上海'',''HTTPS'',''0.269秒'',''14天'',''17-11-27 0' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '115.202.251.191',
 'port': '34648',
 'proof_time': '17-11-27 00:00',
 'speed': '1.44秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.202.251.191'',''34648'',''浙江台州'',''HTTPS'',''1.44秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.142',
 'port': '8010',
 'proof_time': '17-11-27 00:00',
 'speed': '2.319秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.118.142'',''8010'',''安徽'',''HTTPS'',''2.319秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '510天',
 'ip': '110.73.13.220',
 'port': '8123',
 'proof_time': '17-11-26 23:46',
 'speed': '1.385秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.13.220'',''8123'',''广西防城港'',''HTTP'',''1.385秒'',''510天'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '8天',
 'ip': '223.241.78.159',
 'port': '8010',
 'proof_time': '17-11-26 23:45',
 'speed': '7.697秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.159'',''8010'',''安徽芜湖'',''HTTP'',''7.697秒'',''8天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '9小时',
 'ip': '221.233.85.178',
 'port': '3128',
 'proof_time': '17-11-26 23:34',
 'speed': '0.219秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '221.233.85.178'',''3128'',''湖北襄阳'',''HTTPS'',''0.219秒'',''9小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:16 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '1分钟',
 'ip': '110.73.12.87',
 'port': '8123',
 'proof_time': '17-11-26 23:33',
 'speed': '7.033秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.12.87'',''8123'',''广西防城港'',''HTTPS'',''7.033秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '2天',
 'ip': '219.138.58.245',
 'port': '3128',
 'proof_time': '17-11-26 23:33',
 'speed': '2.737秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.245'',''3128'',''湖北襄阳'',''HTTP'',''2.737秒'',''2天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.40.30',
 'port': '8123',
 'proof_time': '17-11-26 23:22',
 'speed': '0.574秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.40.30'',''8123'',''广西南宁'',''HTTPS'',''0.574秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江舟山',
 'alive_time': '1分钟',
 'ip': '123.96.4.221',
 'port': '49466',
 'proof_time': '17-11-26 23:22',
 'speed': '1.158秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.96.4.221'',''49466'',''浙江舟山'',''HTTPS'',''1.158秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建龙岩',
 'alive_time': '1分钟',
 'ip': '59.58.242.45',
 'port': '38785',
 'proof_time': '17-11-26 23:16',
 'speed': '0.335秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '59.58.242.45'',''38785'',''福建龙岩'',''HTTP'',''0.335秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏淮安',
 'alive_time': '1分钟',
 'ip': '49.87.176.128',
 'port': '42125',
 'proof_time': '17-11-26 23:16',
 'speed': '0.72秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '49.87.176.128'',''42125'',''江苏淮安'',''HTTP'',''0.72秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '49.81.35.215',
 'port': '38349',
 'proof_time': '17-11-26 23:16',
 'speed': '2.751秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '49.81.35.215'',''38349'',''江苏徐州'',''HTTP'',''2.751秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '108天',
 'ip': '112.114.98.197',
 'port': '8118',
 'proof_time': '17-11-26 22:56',
 'speed': '1.831秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.98.197'',''8118'',''云南临沧'',''HTTP'',''1.831秒'',''108天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏无锡',
 'alive_time': '1分钟',
 'ip': '222.191.169.153',
 'port': '49616',
 'proof_time': '17-11-26 22:55',
 'speed': '1.47秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '222.191.169.153'',''49616'',''江苏无锡'',''HTTPS'',''1.47秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '60.169.217.210',
 'port': '42112',
 'proof_time': '17-11-26 22:55',
 'speed': '0.692秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '60.169.217.210'',''42112'',''安徽'',''HTTPS'',''0.692秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽宿州',
 'alive_time': '1分钟',
 'ip': '60.175.197.108',
 'port': '49585',
 'proof_time': '17-11-26 22:55',
 'speed': '0.153秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '60.175.197.108'',''49585'',''安徽宿州'',''HTTPS'',''0.153秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '28分钟',
 'ip': '120.24.217.220',
 'port': '8080',
 'proof_time': '17-11-26 22:24',
 'speed': '0.149秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '120.24.217.220'',''8080'',''北京'',''HTTPS'',''0.149秒'',''28分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '715天',
 'ip': '110.73.52.184',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '6.448秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.52.184'',''8123'',''广西南宁'',''HTTP'',''6.448秒'',''715天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.110.75',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '7.749秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.110.75'',''8123'',''广西南宁'',''HTTP'',''7.749秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '25天',
 'ip': '121.31.100.168',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '6.172秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.100.168'',''8123'',''广西防城港'',''HTTPS'',''6.172秒'',''25天'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '729天',
 'ip': '110.73.7.113',
 'port': '8123',
 'proof_time': '17-11-26 22:11',
 'speed': '3.722秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.7.113'',''8123'',''广西防城港'',''HTTP'',''3.722秒'',''729天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '40分钟',
 'ip': '110.73.31.159',
 'port': '8123',
 'proof_time': '17-11-26 21:55',
 'speed': '3.117秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.31.159'',''8123'',''广西防城港'',''HTTP'',''3.117秒'',''40分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西',
 'alive_time': '1分钟',
 'ip': '171.37.192.121',
 'port': '8123',
 'proof_time': '17-11-26 21:55',
 'speed': '4.771秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.37.192.121'',''8123'',''广西'',''HTTPS'',''4.771秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '41分钟',
 'ip': '115.46.97.171',
 'port': '8123',
 'proof_time': '17-11-26 21:52',
 'speed': '2.297秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.97.171'',''8123'',''广西南宁'',''HTTPS'',''2.297秒'',''41分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南',
 'alive_time': '185天',
 'ip': '171.13.37.14',
 'port': '808',
 'proof_time': '17-11-26 21:46',
 'speed': '1.817秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.13.37.14'',''808'',''河南'',''HTTPS'',''1.817秒'',''185天'',''17-11-26 2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.53.95',
 'port': '8123',
 'proof_time': '17-11-26 21:44',
 'speed': '4.227秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.53.95'',''8123'',''广西南宁'',''HTTPS'',''4.227秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '',
 'alive_time': '12天',
 'ip': '106.14.241.155',
 'port': '80',
 'proof_time': '17-11-26 21:33',
 'speed': '0.117秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '106.14.241.155'',''80'','''',''HTTPS'',''0.117秒'',''12天'',''17-11-26 21:33''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '751天',
 'ip': '110.72.45.82',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '4.145秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.45.82'',''8123'',''广西贵港'',''HTTP'',''4.145秒'',''751天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西百色',
 'alive_time': '1分钟',
 'ip': '171.39.29.43',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '2.169秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.39.29.43'',''8123'',''广西百色'',''HTTP'',''2.169秒'',''1分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北武汉',
 'alive_time': '1分钟',
 'ip': '27.19.48.74',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '0.121秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '27.19.48.74'',''8123'',''湖北武汉'',''HTTP'',''0.121秒'',''1分钟'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '60.179.41.175',
 'port': '35037',
 'proof_time': '17-11-26 21:22',
 'speed': '0.242秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '60.179.41.175'',''35037'',''浙江宁波'',''HTTPS'',''0.242秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '333天',
 'ip': '110.73.3.86',
 'port': '8123',
 'proof_time': '17-11-26 21:22',
 'speed': '4.002秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.3.86'',''8123'',''广西防城港'',''HTTP'',''4.002秒'',''333天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '585天',
 'ip': '110.73.51.71',
 'port': '8123',
 'proof_time': '17-11-26 21:15',
 'speed': '7.563秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.51.71'',''8123'',''广西南宁'',''HTTP'',''7.563秒'',''585天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '7天',
 'ip': '183.172.129.26',
 'port': '8118',
 'proof_time': '17-11-26 21:11',
 'speed': '1.801秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '183.172.129.26'',''8118'',''北京'',''HTTPS'',''1.801秒'',''7天'',''17-11-26 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西',
 'alive_time': '23分钟',
 'ip': '171.39.236.9',
 'port': '8123',
 'proof_time': '17-11-26 20:45',
 'speed': '0.326秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.39.236.9'',''8123'',''广西'',''HTTPS'',''0.326秒'',''23分钟'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '海南三亚',
 'alive_time': '4小时',
 'ip': '119.41.200.20',
 'port': '53281',
 'proof_time': '17-11-26 20:38',
 'speed': '0.909秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '119.41.200.20'',''53281'',''海南三亚'',''HTTPS'',''0.909秒'',''4小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '1天',
 'ip': '221.233.85.31',
 'port': '3128',
 'proof_time': '17-11-26 20:36',
 'speed': '1.007秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '221.233.85.31'',''3128'',''湖北襄阳'',''HTTP'',''1.007秒'',''1天'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '22分钟',
 'ip': '182.90.109.142',
 'port': '8123',
 'proof_time': '17-11-26 20:33',
 'speed': '2.767秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.109.142'',''8123'',''广西梧州'',''HTTPS'',''2.767秒'',''22分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '752天',
 'ip': '121.31.101.158',
 'port': '8123',
 'proof_time': '17-11-26 20:33',
 'speed': '0.655秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.101.158'',''8123'',''广西防城港'',''HTTP'',''0.655秒'',''752天'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '19分钟',
 'ip': '182.90.69.228',
 'port': '8123',
 'proof_time': '17-11-26 20:30',
 'speed': '7.806秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.69.228'',''8123'',''广西梧州'',''HTTPS'',''7.806秒'',''19分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东济南',
 'alive_time': '1分钟',
 'ip': '122.4.45.172',
 'port': '49759',
 'proof_time': '17-11-26 20:16',
 'speed': '3.61秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.4.45.172'',''49759'',''山东济南'',''HTTP'',''3.61秒'',''1分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.176.190',
 'port': '8123',
 'proof_time': '17-11-26 20:15',
 'speed': '0.77秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.176.190'',''8123'',''广西北海'',''HTTP'',''0.77秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东江门',
 'alive_time': '1分钟',
 'ip': '61.143.16.165',
 'port': '24962',
 'proof_time': '17-11-26 20:15',
 'speed': '0.19秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '61.143.16.165'',''24962'',''广东江门'',''HTTP'',''0.19秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东',
 'alive_time': '1分钟',
 'ip': '140.250.135.166',
 'port': '44114',
 'proof_time': '17-11-26 20:15',
 'speed': '1.811秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '140.250.135.166'',''44114'',''山东'',''HTTP'',''1.811秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '1分钟',
 'ip': '112.114.79.237',
 'port': '8118',
 'proof_time': '17-11-26 20:11',
 'speed': '0.325秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.79.237'',''8118'',''云南临沧'',''HTTPS'',''0.325秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:17 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.112',
 'port': '8010',
 'proof_time': '17-11-26 20:11',
 'speed': '2.624秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.112'',''8010'',''安徽'',''HTTPS'',''2.624秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/3> (referer: http://www.xicidaili.com/nn/2)
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏苏州',
 'alive_time': '1分钟',
 'ip': '49.72.71.95',
 'port': '808',
 'proof_time': '17-11-26 20:11',
 'speed': '1.405秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '49.72.71.95'',''808'',''江苏苏州'',''HTTPS'',''1.405秒'',''1分钟'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '688天',
 'ip': '110.72.33.211',
 'port': '8123',
 'proof_time': '17-11-26 20:11',
 'speed': '7.743秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.33.211'',''8123'',''广西贵港'',''HTTP'',''7.743秒'',''688天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '30天',
 'ip': '121.31.140.60',
 'port': '8123',
 'proof_time': '17-11-26 20:00',
 'speed': '5.223秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.140.60'',''8123'',''广西北海'',''HTTP'',''5.223秒'',''30天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '122天',
 'ip': '112.114.99.145',
 'port': '8118',
 'proof_time': '17-11-26 20:00',
 'speed': '1.34秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.99.145'',''8118'',''云南临沧'',''HTTPS'',''1.34秒'',''122天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '183.149.226.254',
 'port': '37914',
 'proof_time': '17-11-26 19:55',
 'speed': '0.647秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '183.149.226.254'',''37914'',''浙江台州'',''HTTPS'',''0.647秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '541天',
 'ip': '110.73.34.18',
 'port': '8123',
 'proof_time': '17-11-26 19:55',
 'speed': '3.49秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.34.18'',''8123'',''广西防城港'',''HTTP'',''3.49秒'',''541天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东江门市新会区',
 'alive_time': '6分钟',
 'ip': '218.14.141.184',
 'port': '49910',
 'proof_time': '17-11-26 19:50',
 'speed': '0.221秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '218.14.141.184'',''49910'',''广东江门市新会区'',''HTTPS'',''0.221秒'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1天',
 'ip': '223.241.78.144',
 'port': '8010',
 'proof_time': '17-11-26 19:46',
 'speed': '1.993秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.144'',''8010'',''安徽芜湖'',''HTTPS'',''1.993秒'',''1天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.90.87',
 'port': '29283',
 'proof_time': '17-11-26 19:45',
 'speed': '1.998秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '122.242.90.87'',''29283'',''浙江金华'',''HTTPS'',''1.998秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '四川内江',
 'alive_time': '763天',
 'ip': '221.10.159.234',
 'port': '1337',
 'proof_time': '17-11-26 19:28',
 'speed': '0.447秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '221.10.159.234'',''1337'',''四川内江'',''HTTP'',''0.447秒'',''763天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '2天',
 'ip': '223.241.116.149',
 'port': '8010',
 'proof_time': '17-11-26 19:15',
 'speed': '6.221秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.149'',''8010'',''安徽'',''HTTPS'',''6.221秒'',''2天'',''17-11-26' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏盐城',
 'alive_time': '16分钟',
 'ip': '121.234.118.67',
 'port': '23447',
 'proof_time': '17-11-26 19:01',
 'speed': '0.507秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.234.118.67'',''23447'',''江苏盐城'',''HTTPS'',''0.507秒'',''16分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '4天',
 'ip': '219.138.58.52',
 'port': '3128',
 'proof_time': '17-11-26 18:55',
 'speed': '1.851秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.52'',''3128'',''湖北襄阳'',''HTTPS'',''1.851秒'',''4天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '10小时',
 'ip': '112.114.99.84',
 'port': '8118',
 'proof_time': '17-11-26 18:52',
 'speed': '0.373秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.99.84'',''8118'',''云南临沧'',''HTTP'',''0.373秒'',''10小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '31分钟',
 'ip': '223.241.117.122',
 'port': '8010',
 'proof_time': '17-11-26 18:47',
 'speed': '7.525秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.117.122'',''8010'',''安徽'',''HTTP'',''7.525秒'',''31分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.119.167',
 'port': '8010',
 'proof_time': '17-11-26 18:33',
 'speed': '3.232秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.167'',''8010'',''安徽'',''HTTPS'',''3.232秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '180.155.139.172',
 'port': '21494',
 'proof_time': '17-11-26 18:33',
 'speed': '0.161秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.155.139.172'',''21494'',''上海'',''HTTPS'',''0.161秒'',''1分钟'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏常州',
 'alive_time': '12小时',
 'ip': '121.231.226.177',
 'port': '6666',
 'proof_time': '17-11-26 18:31',
 'speed': '0.387秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.231.226.177'',''6666'',''江苏常州'',''HTTPS'',''0.387秒'',''12小时'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '125.112.194.167',
 'port': '40133',
 'proof_time': '17-11-26 18:16',
 'speed': '1.514秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '125.112.194.167'',''40133'',''浙江金华'',''HTTP'',''1.514秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.105.86',
 'port': '8123',
 'proof_time': '17-11-26 18:15',
 'speed': '7.984秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.105.86'',''8123'',''广西梧州'',''HTTP'',''7.984秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:28 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '114天',
 'ip': '219.138.58.119',
 'port': '3128',
 'proof_time': '17-11-26 18:14',
 'speed': '1.06秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.119'',''3128'',''湖北襄阳'',''HTTPS'',''1.06秒'',''114天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:28 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '山东济宁',
 'alive_time': '8小时',
 'ip': '113.120.183.26',
 'port': '808',
 'proof_time': '17-11-26 17:33',
 'speed': '0.109秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '113.120.183.26'',''808'',''山东济宁'',''HTTPS'',''0.109秒'',''8小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '8天',
 'ip': '223.241.117.137',
 'port': '8010',
 'proof_time': '17-11-26 17:30',
 'speed': '1.701秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.117.137'',''8010'',''安徽'',''HTTPS'',''1.701秒'',''8天'',''17-11-26' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东深圳',
 'alive_time': '23小时',
 'ip': '116.25.251.21',
 'port': '8088',
 'proof_time': '17-11-26 17:24',
 'speed': '6.221秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '116.25.251.21'',''8088'',''广东深圳'',''HTTPS'',''6.221秒'',''23小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '2小时',
 'ip': '223.241.117.2',
 'port': '8010',
 'proof_time': '17-11-26 17:11',
 'speed': '6.832秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.117.2'',''8010'',''安徽'',''HTTP'',''6.832秒'',''2小时'',''17-11-26' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '北京',
 'alive_time': '1分钟',
 'ip': '183.172.178.147',
 'port': '8118',
 'proof_time': '17-11-26 17:11',
 'speed': '0.17秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '183.172.178.147'',''8118'',''北京'',''HTTPS'',''0.17秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏镇江',
 'alive_time': '11小时',
 'ip': '180.118.243.24',
 'port': '61234',
 'proof_time': '17-11-26 17:10',
 'speed': '5.475秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.118.243.24'',''61234'',''江苏镇江'',''HTTPS'',''5.475秒'',''11小时'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建莆田',
 'alive_time': '1分钟',
 'ip': '110.85.89.213',
 'port': '44033',
 'proof_time': '17-11-26 16:55',
 'speed': '2.106秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.85.89.213'',''44033'',''福建莆田'',''HTTPS'',''2.106秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '湖北襄阳',
 'alive_time': '4天',
 'ip': '219.138.58.143',
 'port': '3128',
 'proof_time': '17-11-26 16:54',
 'speed': '0.979秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '219.138.58.143'',''3128'',''湖北襄阳'',''HTTPS'',''0.979秒'',''4天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南开封',
 'alive_time': '1分钟',
 'ip': '123.55.157.112',
 'port': '808',
 'proof_time': '17-11-26 16:45',
 'speed': '0.113秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.55.157.112'',''808'',''河南开封'',''HTTPS'',''0.113秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '3小时',
 'ip': '223.241.78.218',
 'port': '8010',
 'proof_time': '17-11-26 16:45',
 'speed': '2.857秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.218'',''8010'',''安徽芜湖'',''HTTP'',''2.857秒'',''3小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '14分钟',
 'ip': '182.90.106.250',
 'port': '8123',
 'proof_time': '17-11-26 16:44',
 'speed': '0.32秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.106.250'',''8123'',''广西梧州'',''HTTP'',''0.32秒'',''14分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '8天',
 'ip': '223.241.119.221',
 'port': '8010',
 'proof_time': '17-11-26 16:33',
 'speed': '2.378秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.221'',''8010'',''安徽'',''HTTPS'',''2.378秒'',''8天'',''17-11-26' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '488天',
 'ip': '110.73.55.76',
 'port': '8123',
 'proof_time': '17-11-26 16:33',
 'speed': '5.859秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.55.76'',''8123'',''广西南宁'',''HTTP'',''5.859秒'',''488天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.173.215',
 'port': '8123',
 'proof_time': '17-11-26 16:33',
 'speed': '0.372秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.173.215'',''8123'',''广西北海'',''HTTPS'',''0.372秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '78天',
 'ip': '110.73.49.124',
 'port': '8123',
 'proof_time': '17-11-26 16:30',
 'speed': '6.021秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.49.124'',''8123'',''广西南宁'',''HTTPS'',''6.021秒'',''78天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '天津',
 'alive_time': '59分钟',
 'ip': '180.213.192.104',
 'port': '8123',
 'proof_time': '17-11-26 16:30',
 'speed': '7.976秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.213.192.104'',''8123'',''天津'',''HTTP'',''7.976秒'',''59分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.52',
 'port': '8010',
 'proof_time': '17-11-26 16:30',
 'speed': '1.966秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.52'',''8010'',''安徽'',''HTTP'',''1.966秒'',''1分钟'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏镇江',
 'alive_time': '144天',
 'ip': '180.118.241.123',
 'port': '808',
 'proof_time': '17-11-26 16:00',
 'speed': '0.427秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.118.241.123'',''808'',''江苏镇江'',''HTTPS'',''0.427秒'',''144天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '620天',
 'ip': '110.73.0.127',
 'port': '8123',
 'proof_time': '17-11-26 16:00',
 'speed': '0.329秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.0.127'',''8123'',''广西防城港'',''HTTP'',''0.329秒'',''620天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏徐州',
 'alive_time': '153天',
 'ip': '180.124.188.50',
 'port': '808',
 'proof_time': '17-11-26 15:57',
 'speed': '0.198秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '180.124.188.50'',''808'',''江苏徐州'',''HTTPS'',''0.198秒'',''153天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.220',
 'port': '8010',
 'proof_time': '17-11-26 15:55',
 'speed': '2.35秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.118.220'',''8010'',''安徽'',''HTTPS'',''2.35秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏宿迁市泗阳县',
 'alive_time': '53天',
 'ip': '114.239.151.90',
 'port': '36572',
 'proof_time': '17-11-26 15:55',
 'speed': '0.557秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.239.151.90'',''36572'',''江苏宿迁市泗阳县'',''HTTPS'',''0.557秒'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '115.202.235.45',
 'port': '41663',
 'proof_time': '17-11-26 15:45',
 'speed': '2.583秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.202.235.45'',''41663'',''浙江台州'',''HTTPS'',''2.583秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '231天',
 'ip': '115.217.255.153',
 'port': '808',
 'proof_time': '17-11-26 15:45',
 'speed': '5.572秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.217.255.153'',''808'',''浙江宁波'',''HTTPS'',''5.572秒'',''231天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '218.73.130.89',
 'port': '39066',
 'proof_time': '17-11-26 15:45',
 'speed': '0.254秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '218.73.130.89'',''39066'',''浙江温州'',''HTTPS'',''0.254秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '114.226.163.52',
 'port': '35598',
 'proof_time': '17-11-26 15:45',
 'speed': '0.228秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '114.226.163.52'',''35598'',''江苏常州'',''HTTPS'',''0.228秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '222.187.166.237',
 'port': '25431',
 'proof_time': '17-11-26 15:45',
 'speed': '0.19秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '222.187.166.237'',''25431'',''江苏徐州'',''HTTPS'',''0.19秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.177.23',
 'port': '8123',
 'proof_time': '17-11-26 15:44',
 'speed': '2.127秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.177.23'',''8123'',''广西北海'',''HTTPS'',''2.127秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西桂林',
 'alive_time': '655天',
 'ip': '121.31.193.203',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '3.247秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.193.203'',''8123'',''广西桂林'',''HTTP'',''3.247秒'',''655天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '3分钟',
 'ip': '110.72.23.44',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '0.987秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.23.44'',''8123'',''广西贵港'',''HTTP'',''0.987秒'',''3分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '2分钟',
 'ip': '182.88.129.91',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '0.276秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.88.129.91'',''8123'',''广西南宁'',''HTTP'',''0.276秒'',''2分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '447天',
 'ip': '121.31.101.86',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '2.447秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.101.86'',''8123'',''广西防城港'',''HTTP'',''2.447秒'',''447天'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '743天',
 'ip': '182.88.179.98',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '3.439秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.88.179.98'',''8123'',''广西南宁'',''HTTP'',''3.439秒'',''743天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南新乡',
 'alive_time': '1分钟',
 'ip': '123.55.89.195',
 'port': '37330',
 'proof_time': '17-11-26 15:33',
 'speed': '0.24秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.55.89.195'',''37330'',''河南新乡'',''HTTPS'',''0.24秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '266天',
 'ip': '182.90.48.24',
 'port': '8123',
 'proof_time': '17-11-26 15:31',
 'speed': '4.723秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '182.90.48.24'',''8123'',''广西梧州'',''HTTP'',''4.723秒'',''266天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '519天',
 'ip': '121.31.101.38',
 'port': '8123',
 'proof_time': '17-11-26 15:31',
 'speed': '5.339秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.101.38'',''8123'',''广西防城港'',''HTTP'',''5.339秒'',''519天'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '2小时',
 'ip': '223.241.119.15',
 'port': '8010',
 'proof_time': '17-11-26 15:31',
 'speed': '5.847秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.15'',''8010'',''安徽'',''HTTPS'',''5.847秒'',''2小时'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '1分钟',
 'ip': '110.73.4.88',
 'port': '8123',
 'proof_time': '17-11-26 15:30',
 'speed': '7.944秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.4.88'',''8123'',''广西防城港'',''HTTP'',''7.944秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.127',
 'port': '8010',
 'proof_time': '17-11-26 15:22',
 'speed': '4.026秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.79.127'',''8010'',''安徽芜湖'',''HTTPS'',''4.026秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.117.49',
 'port': '8010',
 'proof_time': '17-11-26 15:22',
 'speed': '3.079秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.117.49'',''8010'',''安徽'',''HTTPS'',''3.079秒'',''1分钟'',''17-11-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.31.210',
 'port': '8123',
 'proof_time': '17-11-26 15:22',
 'speed': '0.857秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.31.210'',''8123'',''广西贵港'',''HTTPS'',''0.857秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '120.37.164.86',
 'port': '37783',
 'proof_time': '17-11-26 15:15',
 'speed': '0.183秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '120.37.164.86'',''37783'',''福建泉州'',''HTTP'',''0.183秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '5天',
 'ip': '223.241.79.160',
 'port': '8010',
 'proof_time': '17-11-26 15:00',
 'speed': '5.107秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.79.160'',''8010'',''安徽芜湖'',''HTTPS'',''5.107秒'',''5天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.116.241',
 'port': '8010',
 'proof_time': '17-11-26 14:46',
 'speed': '5.248秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.116.241'',''8010'',''安徽'',''HTTPS'',''5.248秒'',''7天'',''17-11-26' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.119.127',
 'port': '8010',
 'proof_time': '17-11-26 14:44',
 'speed': '2.111秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.127'',''8010'',''安徽'',''HTTP'',''2.111秒'',''7天'',''17-11-26 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西北海',
 'alive_time': '691天',
 'ip': '121.31.197.24',
 'port': '8123',
 'proof_time': '17-11-26 14:33',
 'speed': '6.529秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.197.24'',''8123'',''广西北海'',''HTTP'',''6.529秒'',''691天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.33.204',
 'port': '8123',
 'proof_time': '17-11-26 14:22',
 'speed': '3.096秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.33.204'',''8123'',''广西贵港'',''HTTPS'',''3.096秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽芜湖',
 'alive_time': '14天',
 'ip': '223.241.78.206',
 'port': '8010',
 'proof_time': '17-11-26 14:22',
 'speed': '6.24秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.78.206'',''8010'',''安徽芜湖'',''HTTPS'',''6.24秒'',''14天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '7小时',
 'ip': '112.114.99.50',
 'port': '8118',
 'proof_time': '17-11-26 14:16',
 'speed': '0.329秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.99.50'',''8118'',''云南临沧'',''HTTP'',''0.329秒'',''7小时'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '10天',
 'ip': '223.241.117.85',
 'port': '8010',
 'proof_time': '17-11-26 14:15',
 'speed': '6.304秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.117.85'',''8010'',''安徽'',''HTTPS'',''6.304秒'',''10天'',''17-11-26' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '121.31.81.102',
 'port': '8123',
 'proof_time': '17-11-26 14:15',
 'speed': '0.423秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.81.102'',''8123'',''广西梧州'',''HTTP'',''0.423秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '四川德阳',
 'alive_time': '1分钟',
 'ip': '110.189.207.39',
 'port': '48622',
 'proof_time': '17-11-26 14:15',
 'speed': '0.728秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.189.207.39'',''48622'',''四川德阳'',''HTTP'',''0.728秒'',''1分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西',
 'alive_time': '102天',
 'ip': '171.108.205.85',
 'port': '53281',
 'proof_time': '17-11-26 14:15',
 'speed': '0.55秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '171.108.205.85'',''53281'',''广西'',''HTTPS'',''0.55秒'',''102天'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:29 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '688天',
 'ip': '110.73.35.51',
 'port': '8123',
 'proof_time': '17-11-26 14:11',
 'speed': '1.264秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.35.51'',''8123'',''广西防城港'',''HTTP'',''1.264秒'',''688天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:29 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.45.159',
 'port': '8123',
 'proof_time': '17-11-26 14:00',
 'speed': '3.583秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.72.45.159'',''8123'',''广西贵港'',''HTTP'',''3.583秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '福建厦门',
 'alive_time': '2天',
 'ip': '120.32.208.19',
 'port': '8118',
 'proof_time': '17-11-26 14:00',
 'speed': '0.172秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '120.32.208.19'',''8118'',''福建厦门'',''HTTPS'',''0.172秒'',''2天'',''17-1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.55.200.32',
 'port': '38406',
 'proof_time': '17-11-26 13:55',
 'speed': '0.305秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '42.55.200.32'',''38406'',''辽宁'',''HTTPS'',''0.305秒'',''1分钟'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '49.81.10.118',
 'port': '46290',
 'proof_time': '17-11-26 13:55',
 'speed': '0.644秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '49.81.10.118'',''46290'',''江苏徐州'',''HTTPS'',''0.644秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏',
 'alive_time': '1分钟',
 'ip': '121.226.163.85',
 'port': '32181',
 'proof_time': '17-11-26 13:55',
 'speed': '0.164秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.226.163.85'',''32181'',''江苏'',''HTTPS'',''0.164秒'',''1分钟'',''17-11' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江温州',
 'alive_time': '6分钟',
 'ip': '218.73.134.89',
 'port': '49015',
 'proof_time': '17-11-26 13:50',
 'speed': '1.184秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '218.73.134.89'',''49015'',''浙江温州'',''HTTPS'',''1.184秒'',''6分钟'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江舟山',
 'alive_time': '1分钟',
 'ip': '115.209.179.186',
 'port': '37433',
 'proof_time': '17-11-26 13:46',
 'speed': '1.832秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.209.179.186'',''37433'',''浙江舟山'',''HTTPS'',''1.832秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '27天',
 'ip': '115.217.253.77',
 'port': '30580',
 'proof_time': '17-11-26 13:46',
 'speed': '2.145秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.217.253.77'',''30580'',''浙江宁波'',''HTTPS'',''2.145秒'',''27天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.254.132',
 'port': '33222',
 'proof_time': '17-11-26 13:46',
 'speed': '0.199秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.217.254.132'',''33222'',''浙江宁波'',''HTTPS'',''0.199秒'',''1分钟'',' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '浙江丽水',
 'alive_time': '1分钟',
 'ip': '115.226.151.41',
 'port': '22042',
 'proof_time': '17-11-26 13:46',
 'speed': '2.174秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.226.151.41'',''22042'',''浙江丽水'',''HTTPS'',''2.174秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '634天',
 'ip': '110.73.1.23',
 'port': '8123',
 'proof_time': '17-11-26 13:33',
 'speed': '4.967秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.1.23'',''8123'',''广西防城港'',''HTTP'',''4.967秒'',''634天'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '河南开封',
 'alive_time': '19小时',
 'ip': '123.163.137.56',
 'port': '808',
 'proof_time': '17-11-26 13:18',
 'speed': '0.119秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '123.163.137.56'',''808'',''河南开封'',''HTTP'',''0.119秒'',''19小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '121.231.144.19',
 'port': '6666',
 'proof_time': '17-11-26 13:16',
 'speed': '0.132秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.231.144.19'',''6666'',''江苏常州'',''HTTP'',''0.132秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西梧州',
 'alive_time': '328天',
 'ip': '121.31.79.116',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '5.141秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.31.79.116'',''8123'',''广西梧州'',''HTTP'',''5.141秒'',''328天'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '583天',
 'ip': '110.73.8.229',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '3.229秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.8.229'',''8123'',''广西防城港'',''HTTP'',''3.229秒'',''583天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.119.101',
 'port': '8010',
 'proof_time': '17-11-26 13:15',
 'speed': '4.57秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.101'',''8010'',''安徽'',''HTTP'',''4.57秒'',''1分钟'',''17-11-2' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.76.45',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '1.934秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '115.46.76.45'',''8123'',''广西南宁'',''HTTP'',''1.934秒'',''1分钟'',''17-' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '327天',
 'ip': '110.73.7.140',
 'port': '8123',
 'proof_time': '17-11-26 13:11',
 'speed': '6.031秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.7.140'',''8123'',''广西防城港'',''HTTP'',''6.031秒'',''327天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广西防城港',
 'alive_time': '648天',
 'ip': '110.73.4.128',
 'port': '8123',
 'proof_time': '17-11-26 13:11',
 'speed': '6.114秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '110.73.4.128'',''8123'',''广西防城港'',''HTTP'',''6.114秒'',''648天'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '云南临沧',
 'alive_time': '17小时',
 'ip': '112.114.93.56',
 'port': '8118',
 'proof_time': '17-11-26 13:09',
 'speed': '0.418秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '112.114.93.56'',''8118'',''云南临沧'',''HTTPS'',''0.418秒'',''17小时'',''' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '安徽',
 'alive_time': '6天',
 'ip': '223.241.119.13',
 'port': '8010',
 'proof_time': '17-11-26 13:00',
 'speed': '2.216秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '223.241.119.13'',''8010'',''安徽'',''HTTPS'',''2.216秒'',''6天'',''17-11-26 ' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '121.231.150.223',
 'port': '6666',
 'proof_time': '17-11-26 13:00',
 'speed': '0.149秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '121.231.150.223'',''6666'',''江苏常州'',''HTTPS'',''0.149秒'',''1分钟'','' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东佛山',
 'alive_time': '1分钟',
 'ip': '119.127.17.162',
 'port': '808',
 'proof_time': '17-11-26 13:00',
 'speed': '3.658秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '119.127.17.162'',''808'',''广东佛山'',''HTTP'',''3.658秒'',''1分钟'',''17' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东佛山',
 'alive_time': '1分钟',
 'ip': '119.127.17.162',
 'port': '808',
 'proof_time': '17-11-26 13:00',
 'speed': '3.264秒',
 'style': 'HTTPS'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '119.127.17.162'',''808'',''广东佛山'',''HTTPS'',''3.264秒'',''1分钟'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.scraper] ERROR: Error processing {'addrs': '广东深圳',
 'alive_time': '4小时',
 'ip': '116.30.233.134',
 'port': '8118',
 'proof_time': '17-11-26 12:51',
 'speed': '0.255秒',
 'style': 'HTTP'}
Traceback (most recent call last):
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 28, in process_item
    cur.execute(sql,lis)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 166, in execute
    result = self._query(query)
  File "E:\Anaconda3\lib\site-packages\pymysql\cursors.py", line 322, in _query
    conn.query(q)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 856, in query
    self._affected_rows = self._read_query_result(unbuffered=unbuffered)
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1057, in _read_query_result
    result.read()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1340, in read
    first_packet = self.connection._read_packet()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 1014, in _read_packet
    packet.check_error()
  File "E:\Anaconda3\lib\site-packages\pymysql\connections.py", line 393, in check_error
    err.raise_mysql_exception(self._data)
  File "E:\Anaconda3\lib\site-packages\pymysql\err.py", line 107, in raise_mysql_exception
    raise errorclass(errno, errval)
pymysql.err.ProgrammingError: (1064, "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '116.30.233.134'',''8118'',''广东深圳'',''HTTP'',''0.255秒'',''4小时'',''1' at line 1")

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "E:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 653, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "E:\scrapy_study\collectionips\collectionips\pipelines.py", line 31, in process_item
    log.err(e)
  File "E:\Anaconda3\lib\site-packages\scrapy\log.py", line 59, in err
    message = kw.pop('why', _why) or failure.value
AttributeError: 'ProgrammingError' object has no attribute 'value'
2017-11-27 10:33:30 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:33:30 [scrapy.core.engine] INFO: Closing spider (finished)
2017-11-27 10:33:30 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1372,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 24995,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 200,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 11, 27, 2, 33, 30, 324779),
 'log_count/DEBUG': 106,
 'log_count/ERROR': 300,
 'log_count/INFO': 7,
 'log_count/WARNING': 2,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 11, 27, 2, 33, 3, 590405)}
2017-11-27 10:33:30 [scrapy.core.engine] INFO: Spider closed (finished)
2017-11-27 10:36:48 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: collectionips)
2017-11-27 10:36:48 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'collectionips', 'DEPTH_LIMIT': 2, 'DOWNLOAD_DELAY': 10, 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'collectionips.spiders', 'SPIDER_MODULES': ['collectionips.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0'}
2017-11-27 10:36:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-27 10:36:48 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-27 10:36:48 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-27 10:36:48 [py.warnings] WARNING: E:\scrapy_study\collectionips\collectionips\pipelines.py:11: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-27 10:36:48 [scrapy.middleware] INFO: Enabled item pipelines:
['collectionips.pipelines.CollectionipsPipeline',
 'collectionips.pipelines.MySQLPipeline']
2017-11-27 10:36:48 [scrapy.core.engine] INFO: Spider opened
2017-11-27 10:36:48 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-27 10:36:48 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-11-27 10:36:48 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn> (referer: None)
2017-11-27 10:36:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江杭州',
 'alive_time': '102天',
 'ip': '101.68.73.54',
 'port': '53281',
 'proof_time': '17-11-27 10:30',
 'speed': '0.218秒',
 'style': 'HTTP'}
2017-11-27 10:36:51 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xicidaili.com/nn/2> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-11-27 10:36:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '656天',
 'ip': '110.73.55.126',
 'port': '8123',
 'proof_time': '17-11-27 10:30',
 'speed': '0.3秒',
 'style': 'HTTP'}
2017-11-27 10:36:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '27天',
 'ip': '111.155.116.218',
 'port': '8123',
 'proof_time': '17-11-27 10:30',
 'speed': '1.063秒',
 'style': 'HTTP'}
2017-11-27 10:36:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '辽宁大连',
 'alive_time': '8小时',
 'ip': '113.226.146.239',
 'port': '8080',
 'proof_time': '17-11-27 10:26',
 'speed': '0.104秒',
 'style': 'HTTP'}
2017-11-27 10:36:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '辽宁葫芦岛',
 'alive_time': '3天',
 'ip': '123.56.86.187',
 'port': '3128',
 'proof_time': '17-11-27 10:26',
 'speed': '0.01秒',
 'style': 'HTTPS'}
2017-11-27 10:36:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '10小时',
 'ip': '219.138.58.187',
 'port': '3128',
 'proof_time': '17-11-27 10:25',
 'speed': '0.834秒',
 'style': 'HTTP'}
2017-11-27 10:36:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河南郑州',
 'alive_time': '8小时',
 'ip': '122.114.31.177',
 'port': '808',
 'proof_time': '17-11-27 10:24',
 'speed': '0.107秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '563天',
 'ip': '61.135.217.7',
 'port': '80',
 'proof_time': '17-11-27 10:24',
 'speed': '0.324秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '',
 'alive_time': '1天',
 'ip': '123.207.8.94',
 'port': '8080',
 'proof_time': '17-11-27 10:24',
 'speed': '0.178秒',
 'style': 'HTTPS'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江宁波',
 'alive_time': '2小时',
 'ip': '115.217.25.246',
 'port': '808',
 'proof_time': '17-11-27 10:23',
 'speed': '2.345秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '6小时',
 'ip': '221.233.85.141',
 'port': '3128',
 'proof_time': '17-11-27 10:22',
 'speed': '0.929秒',
 'style': 'HTTPS'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '118天',
 'ip': '112.114.95.56',
 'port': '8118',
 'proof_time': '17-11-27 10:22',
 'speed': '0.328秒',
 'style': 'HTTPS'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '114天',
 'ip': '112.114.96.164',
 'port': '8118',
 'proof_time': '17-11-27 10:18',
 'speed': '0.909秒',
 'style': 'HTTPS'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏扬州',
 'alive_time': '1分钟',
 'ip': '114.230.127.127',
 'port': '23294',
 'proof_time': '17-11-27 10:16',
 'speed': '3.887秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.25.87',
 'port': '8123',
 'proof_time': '17-11-27 10:16',
 'speed': '4.339秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.20.6',
 'port': '8123',
 'proof_time': '17-11-27 10:15',
 'speed': '5.925秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '铁通',
 'alive_time': '1天',
 'ip': '110.216.60.136',
 'port': '80',
 'proof_time': '17-11-27 10:11',
 'speed': '0.347秒',
 'style': 'HTTP'}
2017-11-27 10:36:54 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河北保定',
 'alive_time': '1分钟',
 'ip': '124.237.128.42',
 'port': '9999',
 'proof_time': '17-11-27 10:11',
 'speed': '0.154秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '182.88.187.217',
 'port': '8123',
 'proof_time': '17-11-27 10:11',
 'speed': '0.483秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.20',
 'port': '8010',
 'proof_time': '17-11-27 10:11',
 'speed': '6.217秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '86天',
 'ip': '110.72.17.204',
 'port': '8123',
 'proof_time': '17-11-27 10:11',
 'speed': '3.55秒',
 'style': 'HTTP'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '上海',
 'alive_time': '10小时',
 'ip': '180.175.120.96',
 'port': '51552',
 'proof_time': '17-11-27 10:10',
 'speed': '0.191秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '山西大同',
 'alive_time': '7小时',
 'ip': '118.72.124.97',
 'port': '80',
 'proof_time': '17-11-27 10:09',
 'speed': '0.098秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河南三门峡',
 'alive_time': '21小时',
 'ip': '123.55.190.127',
 'port': '30670',
 'proof_time': '17-11-27 10:04',
 'speed': '0.265秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建泉州',
 'alive_time': '13小时',
 'ip': '117.24.36.67',
 'port': '808',
 'proof_time': '17-11-27 10:03',
 'speed': '3.546秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建龙岩',
 'alive_time': '1分钟',
 'ip': '121.206.87.230',
 'port': '46046',
 'proof_time': '17-11-27 09:55',
 'speed': '0.24秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江杭州',
 'alive_time': '3天',
 'ip': '125.119.160.69',
 'port': '8118',
 'proof_time': '17-11-27 09:47',
 'speed': '2.334秒',
 'style': 'HTTP'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏镇江',
 'alive_time': '2分钟',
 'ip': '180.118.195.69',
 'port': '23959',
 'proof_time': '17-11-27 09:46',
 'speed': '0.54秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '5天',
 'ip': '219.138.58.59',
 'port': '3128',
 'proof_time': '17-11-27 09:45',
 'speed': '1.237秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广东东莞',
 'alive_time': '1小时',
 'ip': '113.79.74.68',
 'port': '808',
 'proof_time': '17-11-27 09:42',
 'speed': '0.224秒',
 'style': 'HTTPS'}
2017-11-27 10:36:55 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '484天',
 'ip': '110.72.22.61',
 'port': '8123',
 'proof_time': '17-11-27 09:41',
 'speed': '0.575秒',
 'style': 'HTTP'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '31天',
 'ip': '120.25.164.134',
 'port': '8118',
 'proof_time': '17-11-27 09:34',
 'speed': '0.239秒',
 'style': 'HTTP'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '230天',
 'ip': '111.155.116.215',
 'port': '8123',
 'proof_time': '17-11-27 09:22',
 'speed': '1.808秒',
 'style': 'HTTP'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '119天',
 'ip': '111.155.116.232',
 'port': '8123',
 'proof_time': '17-11-27 09:21',
 'speed': '2.736秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '100天',
 'ip': '112.114.95.59',
 'port': '8118',
 'proof_time': '17-11-27 09:19',
 'speed': '0.363秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '12小时',
 'ip': '219.138.58.33',
 'port': '3128',
 'proof_time': '17-11-27 09:14',
 'speed': '0.693秒',
 'style': 'HTTP'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江绍兴',
 'alive_time': '7小时',
 'ip': '183.144.192.184',
 'port': '3128',
 'proof_time': '17-11-27 09:12',
 'speed': '0.417秒',
 'style': 'HTTP'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '四川泸州',
 'alive_time': '13天',
 'ip': '218.88.215.109',
 'port': '8118',
 'proof_time': '17-11-27 09:10',
 'speed': '0.263秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江西',
 'alive_time': '7天',
 'ip': '171.35.103.37',
 'port': '808',
 'proof_time': '17-11-27 09:09',
 'speed': '0.196秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.99.227',
 'port': '8118',
 'proof_time': '17-11-27 09:01',
 'speed': '0.343秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '山东日照',
 'alive_time': '5小时',
 'ip': '182.37.117.26',
 'port': '808',
 'proof_time': '17-11-27 08:53',
 'speed': '0.169秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '上海',
 'alive_time': '2天',
 'ip': '58.246.123.42',
 'port': '808',
 'proof_time': '17-11-27 08:53',
 'speed': '0.144秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.97.127',
 'port': '8118',
 'proof_time': '17-11-27 08:51',
 'speed': '0.32秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.252.150',
 'port': '29745',
 'proof_time': '17-11-27 08:46',
 'speed': '0.171秒',
 'style': 'HTTPS'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '22小时',
 'ip': '223.241.119.208',
 'port': '8010',
 'proof_time': '17-11-27 08:46',
 'speed': '7.188秒',
 'style': 'HTTP'}
2017-11-27 10:36:56 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '山东济南',
 'alive_time': '2分钟',
 'ip': '122.4.43.19',
 'port': '42331',
 'proof_time': '17-11-27 08:46',
 'speed': '0.132秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江丽水',
 'alive_time': '2分钟',
 'ip': '115.213.206.220',
 'port': '33904',
 'proof_time': '17-11-27 08:46',
 'speed': '1.251秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江',
 'alive_time': '1分钟',
 'ip': '36.25.111.118',
 'port': '40064',
 'proof_time': '17-11-27 08:45',
 'speed': '0.144秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '483天',
 'ip': '182.88.44.116',
 'port': '8123',
 'proof_time': '17-11-27 08:45',
 'speed': '7.174秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '7天',
 'ip': '223.241.79.224',
 'port': '8010',
 'proof_time': '17-11-27 08:44',
 'speed': '2.11秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.243',
 'port': '8010',
 'proof_time': '17-11-27 08:44',
 'speed': '2.548秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '黑龙江哈尔滨',
 'alive_time': '100天',
 'ip': '125.211.202.26',
 'port': '53281',
 'proof_time': '17-11-27 08:39',
 'speed': '2.836秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建福州',
 'alive_time': '7分钟',
 'ip': '27.156.215.117',
 'port': '39382',
 'proof_time': '17-11-27 08:30',
 'speed': '0.197秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '1小时',
 'ip': '110.72.17.11',
 'port': '8123',
 'proof_time': '17-11-27 08:30',
 'speed': '2.125秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏南通',
 'alive_time': '1分钟',
 'ip': '117.86.204.52',
 'port': '28488',
 'proof_time': '17-11-27 08:22',
 'speed': '0.147秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '29天',
 'ip': '223.241.78.85',
 'port': '8010',
 'proof_time': '17-11-27 08:22',
 'speed': '1.931秒',
 'style': 'HTTPS'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江舟山',
 'alive_time': '6分钟',
 'ip': '123.96.0.101',
 'port': '33042',
 'proof_time': '17-11-27 08:22',
 'speed': '0.26秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西玉林',
 'alive_time': '713天',
 'ip': '171.38.85.125',
 'port': '8123',
 'proof_time': '17-11-27 08:22',
 'speed': '1.077秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏南通',
 'alive_time': '6分钟',
 'ip': '117.86.166.92',
 'port': '20638',
 'proof_time': '17-11-27 08:21',
 'speed': '0.173秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏泰州',
 'alive_time': '1分钟',
 'ip': '180.122.149.206',
 'port': '24295',
 'proof_time': '17-11-27 08:15',
 'speed': '0.153秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '218.81.237.58',
 'port': '22624',
 'proof_time': '17-11-27 08:15',
 'speed': '0.127秒',
 'style': 'HTTP'}
2017-11-27 10:36:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广东茂名',
 'alive_time': '6小时',
 'ip': '113.94.76.14',
 'port': '3128',
 'proof_time': '17-11-27 08:11',
 'speed': '0.2秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '1小时',
 'ip': '221.233.85.110',
 'port': '3128',
 'proof_time': '17-11-27 08:09',
 'speed': '0.71秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '19分钟',
 'ip': '219.138.58.202',
 'port': '3128',
 'proof_time': '17-11-27 08:04',
 'speed': '0.782秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '四川成都',
 'alive_time': '674天',
 'ip': '118.114.77.47',
 'port': '8080',
 'proof_time': '17-11-27 08:01',
 'speed': '3.136秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '17天',
 'ip': '223.241.116.220',
 'port': '8010',
 'proof_time': '17-11-27 07:55',
 'speed': '5.715秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '11小时',
 'ip': '223.241.118.214',
 'port': '8010',
 'proof_time': '17-11-27 07:55',
 'speed': '6.703秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.76.5',
 'port': '8123',
 'proof_time': '17-11-27 07:45',
 'speed': '4.871秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建厦门',
 'alive_time': '357天',
 'ip': '121.204.165.246',
 'port': '8118',
 'proof_time': '17-11-27 07:40',
 'speed': '0.179秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '98天',
 'ip': '118.187.58.34',
 'port': '53281',
 'proof_time': '17-11-27 07:35',
 'speed': '1.137秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.99.147',
 'port': '8123',
 'proof_time': '17-11-27 07:31',
 'speed': '5.513秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.120.40',
 'port': '8123',
 'proof_time': '17-11-27 07:31',
 'speed': '0.328秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏',
 'alive_time': '1分钟',
 'ip': '117.62.177.126',
 'port': '8118',
 'proof_time': '17-11-27 07:22',
 'speed': '4.886秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '34天',
 'ip': '223.241.79.7',
 'port': '8010',
 'proof_time': '17-11-27 07:22',
 'speed': '5.675秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '5小时',
 'ip': '221.233.85.235',
 'port': '3128',
 'proof_time': '17-11-27 07:22',
 'speed': '1.231秒',
 'style': 'HTTPS'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江台州',
 'alive_time': '10小时',
 'ip': '115.203.221.178',
 'port': '8888',
 'proof_time': '17-11-27 07:21',
 'speed': '0.859秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1119天',
 'ip': '60.169.78.218',
 'port': '808',
 'proof_time': '17-11-27 07:21',
 'speed': '2.68秒',
 'style': 'HTTP'}
2017-11-27 10:36:58 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏无锡',
 'alive_time': '1分钟',
 'ip': '114.224.85.225',
 'port': '38954',
 'proof_time': '17-11-27 06:55',
 'speed': '1.259秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '222.79.178.83',
 'port': '45956',
 'proof_time': '17-11-27 06:55',
 'speed': '0.184秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江丽水',
 'alive_time': '1分钟',
 'ip': '115.230.79.93',
 'port': '46297',
 'proof_time': '17-11-27 06:55',
 'speed': '1.76秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建福州',
 'alive_time': '1分钟',
 'ip': '27.156.195.189',
 'port': '40298',
 'proof_time': '17-11-27 06:55',
 'speed': '1.659秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '433天',
 'ip': '202.108.2.42',
 'port': '80',
 'proof_time': '17-11-27 06:39',
 'speed': '5.855秒',
 'style': 'HTTP'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江杭州',
 'alive_time': '229天',
 'ip': '125.120.40.65',
 'port': '808',
 'proof_time': '17-11-27 06:33',
 'speed': '4.099秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.119.63',
 'port': '8010',
 'proof_time': '17-11-27 06:31',
 'speed': '7.536秒',
 'style': 'HTTP'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.91',
 'port': '8010',
 'proof_time': '17-11-27 06:22',
 'speed': '2.714秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '吉林四平',
 'alive_time': '4小时',
 'ip': '122.143.142.25',
 'port': '80',
 'proof_time': '17-11-27 06:17',
 'speed': '0.103秒',
 'style': 'HTTP'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.122',
 'port': '8010',
 'proof_time': '17-11-27 06:15',
 'speed': '1.954秒',
 'style': 'HTTP'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '5天',
 'ip': '223.241.119.198',
 'port': '8010',
 'proof_time': '17-11-27 06:01',
 'speed': '0.52秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '60天',
 'ip': '223.241.116.35',
 'port': '8010',
 'proof_time': '17-11-27 05:55',
 'speed': '5.749秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '36.7.58.8',
 'port': '49151',
 'proof_time': '17-11-27 05:44',
 'speed': '5.252秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '121.205.11.189',
 'port': '29970',
 'proof_time': '17-11-27 05:44',
 'speed': '0.183秒',
 'style': 'HTTPS'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江嘉兴',
 'alive_time': '3分钟',
 'ip': '122.231.32.27',
 'port': '24567',
 'proof_time': '17-11-27 05:33',
 'speed': '0.605秒',
 'style': 'HTTP'}
2017-11-27 10:36:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '114.228.75.179',
 'port': '53650',
 'proof_time': '17-11-27 05:30',
 'speed': '1.897秒',
 'style': 'HTTP'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广东广州',
 'alive_time': '101天',
 'ip': '183.63.140.82',
 'port': '53281',
 'proof_time': '17-11-27 05:22',
 'speed': '0.258秒',
 'style': 'HTTPS'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河南平顶山',
 'alive_time': '1分钟',
 'ip': '123.161.237.255',
 'port': '47565',
 'proof_time': '17-11-27 05:22',
 'speed': '0.13秒',
 'style': 'HTTPS'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.215.51.161',
 'port': '42517',
 'proof_time': '17-11-27 05:22',
 'speed': '0.175秒',
 'style': 'HTTPS'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏常州',
 'alive_time': '6分钟',
 'ip': '218.93.105.98',
 'port': '40260',
 'proof_time': '17-11-27 05:21',
 'speed': '6.653秒',
 'style': 'HTTP'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '天津',
 'alive_time': '1分钟',
 'ip': '180.213.173.19',
 'port': '8123',
 'proof_time': '17-11-27 05:11',
 'speed': '5.964秒',
 'style': 'HTTPS'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.223',
 'port': '8010',
 'proof_time': '17-11-27 05:11',
 'speed': '2.156秒',
 'style': 'HTTPS'}
2017-11-27 10:37:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.177.143.109',
 'port': '49715',
 'proof_time': '17-11-27 04:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
2017-11-27 10:37:03 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/2> (referer: http://www.xicidaili.com/nn)
2017-11-27 10:37:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '甘肃兰州市城关区',
 'alive_time': '633天',
 'ip': '61.178.238.122',
 'port': '63000',
 'proof_time': '17-11-27 04:41',
 'speed': '0.338秒',
 'style': 'HTTP'}
2017-11-27 10:37:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '18天',
 'ip': '223.241.118.61',
 'port': '8010',
 'proof_time': '17-11-27 04:31',
 'speed': '2.004秒',
 'style': 'HTTPS'}
2017-11-27 10:37:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.121',
 'port': '8010',
 'proof_time': '17-11-27 04:31',
 'speed': '0.565秒',
 'style': 'HTTP'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.19',
 'port': '8010',
 'proof_time': '17-11-27 04:11',
 'speed': '7.059秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.93',
 'port': '8010',
 'proof_time': '17-11-27 04:11',
 'speed': '3.515秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.67.22',
 'port': '8123',
 'proof_time': '17-11-27 03:55',
 'speed': '3.294秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '125.112.195.191',
 'port': '46118',
 'proof_time': '17-11-27 03:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '河南平顶山',
 'alive_time': '214天',
 'ip': '222.85.39.20',
 'port': '808',
 'proof_time': '17-11-27 03:55',
 'speed': '1.005秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '222.71.89.136',
 'port': '46443',
 'proof_time': '17-11-27 03:55',
 'speed': '0.126秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '黑龙江',
 'alive_time': '1分钟',
 'ip': '116.62.217.206',
 'port': '80',
 'proof_time': '17-11-27 03:46',
 'speed': '2.201秒',
 'style': 'HTTP'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.254.247',
 'port': '39426',
 'proof_time': '17-11-27 03:46',
 'speed': '0.162秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '',
 'alive_time': '2天',
 'ip': '106.42.97.33',
 'port': '808',
 'proof_time': '17-11-27 03:30',
 'speed': '3.181秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '1天',
 'ip': '183.172.232.222',
 'port': '8118',
 'proof_time': '17-11-27 03:01',
 'speed': '0.145秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '河北保定',
 'alive_time': '1分钟',
 'ip': '124.237.128.148',
 'port': '9999',
 'proof_time': '17-11-27 03:00',
 'speed': '0.111秒',
 'style': 'HTTPS'}
2017-11-27 10:37:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.138.77',
 'port': '8123',
 'proof_time': '17-11-27 03:00',
 'speed': '4.072秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏苏州',
 'alive_time': '1分钟',
 'ip': '222.93.241.22',
 'port': '25206',
 'proof_time': '17-11-27 02:46',
 'speed': '3.017秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.28.161',
 'port': '8123',
 'proof_time': '17-11-27 02:45',
 'speed': '3.304秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '114.234.82.2',
 'port': '36847',
 'proof_time': '17-11-27 02:45',
 'speed': '3.926秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '2分钟',
 'ip': '182.88.179.176',
 'port': '8123',
 'proof_time': '17-11-27 02:33',
 'speed': '4.206秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '陕西渭南',
 'alive_time': '105天',
 'ip': '124.89.33.59',
 'port': '53281',
 'proof_time': '17-11-27 02:31',
 'speed': '0.11秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广东东莞',
 'alive_time': '3小时',
 'ip': '113.77.100.84',
 'port': '3128',
 'proof_time': '17-11-27 02:16',
 'speed': '0.471秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '125.109.197.191',
 'port': '29717',
 'proof_time': '17-11-27 02:16',
 'speed': '0.513秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '382天',
 'ip': '110.73.54.218',
 'port': '8123',
 'proof_time': '17-11-27 02:16',
 'speed': '4.395秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '708天',
 'ip': '121.31.79.243',
 'port': '8123',
 'proof_time': '17-11-27 02:16',
 'speed': '7.653秒',
 'style': 'HTTP'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '4分钟',
 'ip': '110.73.30.100',
 'port': '8123',
 'proof_time': '17-11-27 02:15',
 'speed': '2.91秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.50.90',
 'port': '8123',
 'proof_time': '17-11-27 02:11',
 'speed': '1.482秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '104天',
 'ip': '110.73.30.197',
 'port': '8123',
 'proof_time': '17-11-27 02:11',
 'speed': '3.901秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.79.182',
 'port': '8118',
 'proof_time': '17-11-27 02:09',
 'speed': '0.325秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.71.165',
 'port': '8123',
 'proof_time': '17-11-27 02:01',
 'speed': '2.833秒',
 'style': 'HTTPS'}
2017-11-27 10:37:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西',
 'alive_time': '1分钟',
 'ip': '171.37.171.1',
 'port': '8123',
 'proof_time': '17-11-27 02:00',
 'speed': '0.365秒',
 'style': 'HTTPS'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '552天',
 'ip': '182.90.69.230',
 'port': '8123',
 'proof_time': '17-11-27 01:56',
 'speed': '6.033秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西玉林',
 'alive_time': '1分钟',
 'ip': '171.38.42.238',
 'port': '8123',
 'proof_time': '17-11-27 01:55',
 'speed': '5.622秒',
 'style': 'HTTPS'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西玉林',
 'alive_time': '1分钟',
 'ip': '171.38.65.81',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.276秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西北海',
 'alive_time': '642天',
 'ip': '121.31.144.228',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.354秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.27.175',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '3.756秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '548天',
 'ip': '110.73.55.185',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '4.399秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.79.125',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.262秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.54.115',
 'port': '8123',
 'proof_time': '17-11-27 01:44',
 'speed': '6.044秒',
 'style': 'HTTPS'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '136天',
 'ip': '61.135.155.82',
 'port': '443',
 'proof_time': '17-11-27 01:33',
 'speed': '3.462秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.117.5',
 'port': '8010',
 'proof_time': '17-11-27 01:31',
 'speed': '0.79秒',
 'style': 'HTTP'}
2017-11-27 10:37:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '4分钟',
 'ip': '223.241.116.27',
 'port': '8010',
 'proof_time': '17-11-27 01:15',
 'speed': '2.437秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '54天',
 'ip': '115.46.69.28',
 'port': '8123',
 'proof_time': '17-11-27 01:11',
 'speed': '5.763秒',
 'style': 'HTTP'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '铁通',
 'alive_time': '46天',
 'ip': '114.115.216.99',
 'port': '80',
 'proof_time': '17-11-27 01:08',
 'speed': '0.045秒',
 'style': 'HTTP'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '19天',
 'ip': '223.241.116.88',
 'port': '8010',
 'proof_time': '17-11-27 00:55',
 'speed': '0.694秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '四川德阳',
 'alive_time': '1分钟',
 'ip': '110.189.207.224',
 'port': '37695',
 'proof_time': '17-11-27 00:55',
 'speed': '2.267秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '60.169.216.165',
 'port': '44800',
 'proof_time': '17-11-27 00:55',
 'speed': '0.176秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.219.222',
 'port': '32022',
 'proof_time': '17-11-27 00:55',
 'speed': '0.606秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '114.234.82.127',
 'port': '33375',
 'proof_time': '17-11-27 00:44',
 'speed': '3.91秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.88.181',
 'port': '32473',
 'proof_time': '17-11-27 00:44',
 'speed': '5.954秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东济南',
 'alive_time': '1分钟',
 'ip': '122.4.47.99',
 'port': '38981',
 'proof_time': '17-11-27 00:44',
 'speed': '4.461秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东枣庄',
 'alive_time': '774天',
 'ip': '60.214.118.170',
 'port': '63000',
 'proof_time': '17-11-27 00:42',
 'speed': '0.218秒',
 'style': 'HTTP'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '吉林长春',
 'alive_time': '1小时',
 'ip': '123.173.81.190',
 'port': '80',
 'proof_time': '17-11-27 00:40',
 'speed': '1.406秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '吉林长春',
 'alive_time': '11小时',
 'ip': '58.244.59.208',
 'port': '8080',
 'proof_time': '17-11-27 00:31',
 'speed': '0.088秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '上海',
 'alive_time': '14天',
 'ip': '116.231.35.5',
 'port': '8118',
 'proof_time': '17-11-27 00:23',
 'speed': '0.269秒',
 'style': 'HTTPS'}
2017-11-27 10:37:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '115.202.251.191',
 'port': '34648',
 'proof_time': '17-11-27 00:00',
 'speed': '1.44秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.142',
 'port': '8010',
 'proof_time': '17-11-27 00:00',
 'speed': '2.319秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '510天',
 'ip': '110.73.13.220',
 'port': '8123',
 'proof_time': '17-11-26 23:46',
 'speed': '1.385秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽芜湖',
 'alive_time': '8天',
 'ip': '223.241.78.159',
 'port': '8010',
 'proof_time': '17-11-26 23:45',
 'speed': '7.697秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北襄阳',
 'alive_time': '9小时',
 'ip': '221.233.85.178',
 'port': '3128',
 'proof_time': '17-11-26 23:34',
 'speed': '0.219秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '1分钟',
 'ip': '110.73.12.87',
 'port': '8123',
 'proof_time': '17-11-26 23:33',
 'speed': '7.033秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北襄阳',
 'alive_time': '2天',
 'ip': '219.138.58.245',
 'port': '3128',
 'proof_time': '17-11-26 23:33',
 'speed': '2.737秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.40.30',
 'port': '8123',
 'proof_time': '17-11-26 23:22',
 'speed': '0.574秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江舟山',
 'alive_time': '1分钟',
 'ip': '123.96.4.221',
 'port': '49466',
 'proof_time': '17-11-26 23:22',
 'speed': '1.158秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '福建龙岩',
 'alive_time': '1分钟',
 'ip': '59.58.242.45',
 'port': '38785',
 'proof_time': '17-11-26 23:16',
 'speed': '0.335秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏淮安',
 'alive_time': '1分钟',
 'ip': '49.87.176.128',
 'port': '42125',
 'proof_time': '17-11-26 23:16',
 'speed': '0.72秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '49.81.35.215',
 'port': '38349',
 'proof_time': '17-11-26 23:16',
 'speed': '2.751秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '云南临沧',
 'alive_time': '108天',
 'ip': '112.114.98.197',
 'port': '8118',
 'proof_time': '17-11-26 22:56',
 'speed': '1.831秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏无锡',
 'alive_time': '1分钟',
 'ip': '222.191.169.153',
 'port': '49616',
 'proof_time': '17-11-26 22:55',
 'speed': '1.47秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '60.169.217.210',
 'port': '42112',
 'proof_time': '17-11-26 22:55',
 'speed': '0.692秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽宿州',
 'alive_time': '1分钟',
 'ip': '60.175.197.108',
 'port': '49585',
 'proof_time': '17-11-26 22:55',
 'speed': '0.153秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '28分钟',
 'ip': '120.24.217.220',
 'port': '8080',
 'proof_time': '17-11-26 22:24',
 'speed': '0.149秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '715天',
 'ip': '110.73.52.184',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '6.448秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.110.75',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '7.749秒',
 'style': 'HTTP'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '25天',
 'ip': '121.31.100.168',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '6.172秒',
 'style': 'HTTPS'}
2017-11-27 10:37:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '729天',
 'ip': '110.73.7.113',
 'port': '8123',
 'proof_time': '17-11-26 22:11',
 'speed': '3.722秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '40分钟',
 'ip': '110.73.31.159',
 'port': '8123',
 'proof_time': '17-11-26 21:55',
 'speed': '3.117秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西',
 'alive_time': '1分钟',
 'ip': '171.37.192.121',
 'port': '8123',
 'proof_time': '17-11-26 21:55',
 'speed': '4.771秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '41分钟',
 'ip': '115.46.97.171',
 'port': '8123',
 'proof_time': '17-11-26 21:52',
 'speed': '2.297秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '河南',
 'alive_time': '185天',
 'ip': '171.13.37.14',
 'port': '808',
 'proof_time': '17-11-26 21:46',
 'speed': '1.817秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.53.95',
 'port': '8123',
 'proof_time': '17-11-26 21:44',
 'speed': '4.227秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '',
 'alive_time': '12天',
 'ip': '106.14.241.155',
 'port': '80',
 'proof_time': '17-11-26 21:33',
 'speed': '0.117秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西贵港',
 'alive_time': '751天',
 'ip': '110.72.45.82',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '4.145秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西百色',
 'alive_time': '1分钟',
 'ip': '171.39.29.43',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '2.169秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北武汉',
 'alive_time': '1分钟',
 'ip': '27.19.48.74',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '0.121秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '60.179.41.175',
 'port': '35037',
 'proof_time': '17-11-26 21:22',
 'speed': '0.242秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '333天',
 'ip': '110.73.3.86',
 'port': '8123',
 'proof_time': '17-11-26 21:22',
 'speed': '4.002秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '585天',
 'ip': '110.73.51.71',
 'port': '8123',
 'proof_time': '17-11-26 21:15',
 'speed': '7.563秒',
 'style': 'HTTP'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '7天',
 'ip': '183.172.129.26',
 'port': '8118',
 'proof_time': '17-11-26 21:11',
 'speed': '1.801秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西',
 'alive_time': '23分钟',
 'ip': '171.39.236.9',
 'port': '8123',
 'proof_time': '17-11-26 20:45',
 'speed': '0.326秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '海南三亚',
 'alive_time': '4小时',
 'ip': '119.41.200.20',
 'port': '53281',
 'proof_time': '17-11-26 20:38',
 'speed': '0.909秒',
 'style': 'HTTPS'}
2017-11-27 10:37:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北襄阳',
 'alive_time': '1天',
 'ip': '221.233.85.31',
 'port': '3128',
 'proof_time': '17-11-26 20:36',
 'speed': '1.007秒',
 'style': 'HTTP'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '22分钟',
 'ip': '182.90.109.142',
 'port': '8123',
 'proof_time': '17-11-26 20:33',
 'speed': '2.767秒',
 'style': 'HTTPS'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '752天',
 'ip': '121.31.101.158',
 'port': '8123',
 'proof_time': '17-11-26 20:33',
 'speed': '0.655秒',
 'style': 'HTTP'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '19分钟',
 'ip': '182.90.69.228',
 'port': '8123',
 'proof_time': '17-11-26 20:30',
 'speed': '7.806秒',
 'style': 'HTTPS'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东济南',
 'alive_time': '1分钟',
 'ip': '122.4.45.172',
 'port': '49759',
 'proof_time': '17-11-26 20:16',
 'speed': '3.61秒',
 'style': 'HTTP'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.176.190',
 'port': '8123',
 'proof_time': '17-11-26 20:15',
 'speed': '0.77秒',
 'style': 'HTTP'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广东江门',
 'alive_time': '1分钟',
 'ip': '61.143.16.165',
 'port': '24962',
 'proof_time': '17-11-26 20:15',
 'speed': '0.19秒',
 'style': 'HTTP'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东',
 'alive_time': '1分钟',
 'ip': '140.250.135.166',
 'port': '44114',
 'proof_time': '17-11-26 20:15',
 'speed': '1.811秒',
 'style': 'HTTP'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '云南临沧',
 'alive_time': '1分钟',
 'ip': '112.114.79.237',
 'port': '8118',
 'proof_time': '17-11-26 20:11',
 'speed': '0.325秒',
 'style': 'HTTPS'}
2017-11-27 10:37:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.112',
 'port': '8010',
 'proof_time': '17-11-26 20:11',
 'speed': '2.624秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/3> (referer: http://www.xicidaili.com/nn/2)
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏苏州',
 'alive_time': '1分钟',
 'ip': '49.72.71.95',
 'port': '808',
 'proof_time': '17-11-26 20:11',
 'speed': '1.405秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '688天',
 'ip': '110.72.33.211',
 'port': '8123',
 'proof_time': '17-11-26 20:11',
 'speed': '7.743秒',
 'style': 'HTTP'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '30天',
 'ip': '121.31.140.60',
 'port': '8123',
 'proof_time': '17-11-26 20:00',
 'speed': '5.223秒',
 'style': 'HTTP'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '122天',
 'ip': '112.114.99.145',
 'port': '8118',
 'proof_time': '17-11-26 20:00',
 'speed': '1.34秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '183.149.226.254',
 'port': '37914',
 'proof_time': '17-11-26 19:55',
 'speed': '0.647秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '541天',
 'ip': '110.73.34.18',
 'port': '8123',
 'proof_time': '17-11-26 19:55',
 'speed': '3.49秒',
 'style': 'HTTP'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东江门市新会区',
 'alive_time': '6分钟',
 'ip': '218.14.141.184',
 'port': '49910',
 'proof_time': '17-11-26 19:50',
 'speed': '0.221秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '1天',
 'ip': '223.241.78.144',
 'port': '8010',
 'proof_time': '17-11-26 19:46',
 'speed': '1.993秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.90.87',
 'port': '29283',
 'proof_time': '17-11-26 19:45',
 'speed': '1.998秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '四川内江',
 'alive_time': '763天',
 'ip': '221.10.159.234',
 'port': '1337',
 'proof_time': '17-11-26 19:28',
 'speed': '0.447秒',
 'style': 'HTTP'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '2天',
 'ip': '223.241.116.149',
 'port': '8010',
 'proof_time': '17-11-26 19:15',
 'speed': '6.221秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏盐城',
 'alive_time': '16分钟',
 'ip': '121.234.118.67',
 'port': '23447',
 'proof_time': '17-11-26 19:01',
 'speed': '0.507秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '湖北襄阳',
 'alive_time': '4天',
 'ip': '219.138.58.52',
 'port': '3128',
 'proof_time': '17-11-26 18:55',
 'speed': '1.851秒',
 'style': 'HTTPS'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '10小时',
 'ip': '112.114.99.84',
 'port': '8118',
 'proof_time': '17-11-26 18:52',
 'speed': '0.373秒',
 'style': 'HTTP'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:12 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '31分钟',
 'ip': '223.241.117.122',
 'port': '8010',
 'proof_time': '17-11-26 18:47',
 'speed': '7.525秒',
 'style': 'HTTP'}
2017-11-27 10:37:12 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.119.167',
 'port': '8010',
 'proof_time': '17-11-26 18:33',
 'speed': '3.232秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '180.155.139.172',
 'port': '21494',
 'proof_time': '17-11-26 18:33',
 'speed': '0.161秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '12小时',
 'ip': '121.231.226.177',
 'port': '6666',
 'proof_time': '17-11-26 18:31',
 'speed': '0.387秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '125.112.194.167',
 'port': '40133',
 'proof_time': '17-11-26 18:16',
 'speed': '1.514秒',
 'style': 'HTTP'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.105.86',
 'port': '8123',
 'proof_time': '17-11-26 18:15',
 'speed': '7.984秒',
 'style': 'HTTP'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '湖北襄阳',
 'alive_time': '114天',
 'ip': '219.138.58.119',
 'port': '3128',
 'proof_time': '17-11-26 18:14',
 'speed': '1.06秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '山东济宁',
 'alive_time': '8小时',
 'ip': '113.120.183.26',
 'port': '808',
 'proof_time': '17-11-26 17:33',
 'speed': '0.109秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '8天',
 'ip': '223.241.117.137',
 'port': '8010',
 'proof_time': '17-11-26 17:30',
 'speed': '1.701秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东深圳',
 'alive_time': '23小时',
 'ip': '116.25.251.21',
 'port': '8088',
 'proof_time': '17-11-26 17:24',
 'speed': '6.221秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '2小时',
 'ip': '223.241.117.2',
 'port': '8010',
 'proof_time': '17-11-26 17:11',
 'speed': '6.832秒',
 'style': 'HTTP'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '北京',
 'alive_time': '1分钟',
 'ip': '183.172.178.147',
 'port': '8118',
 'proof_time': '17-11-26 17:11',
 'speed': '0.17秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏镇江',
 'alive_time': '11小时',
 'ip': '180.118.243.24',
 'port': '61234',
 'proof_time': '17-11-26 17:10',
 'speed': '5.475秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '福建莆田',
 'alive_time': '1分钟',
 'ip': '110.85.89.213',
 'port': '44033',
 'proof_time': '17-11-26 16:55',
 'speed': '2.106秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '湖北襄阳',
 'alive_time': '4天',
 'ip': '219.138.58.143',
 'port': '3128',
 'proof_time': '17-11-26 16:54',
 'speed': '0.979秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '河南开封',
 'alive_time': '1分钟',
 'ip': '123.55.157.112',
 'port': '808',
 'proof_time': '17-11-26 16:45',
 'speed': '0.113秒',
 'style': 'HTTPS'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '3小时',
 'ip': '223.241.78.218',
 'port': '8010',
 'proof_time': '17-11-26 16:45',
 'speed': '2.857秒',
 'style': 'HTTP'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '14分钟',
 'ip': '182.90.106.250',
 'port': '8123',
 'proof_time': '17-11-26 16:44',
 'speed': '0.32秒',
 'style': 'HTTP'}
2017-11-27 10:37:13 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:13 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '8天',
 'ip': '223.241.119.221',
 'port': '8010',
 'proof_time': '17-11-26 16:33',
 'speed': '2.378秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '488天',
 'ip': '110.73.55.76',
 'port': '8123',
 'proof_time': '17-11-26 16:33',
 'speed': '5.859秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.173.215',
 'port': '8123',
 'proof_time': '17-11-26 16:33',
 'speed': '0.372秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '78天',
 'ip': '110.73.49.124',
 'port': '8123',
 'proof_time': '17-11-26 16:30',
 'speed': '6.021秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '天津',
 'alive_time': '59分钟',
 'ip': '180.213.192.104',
 'port': '8123',
 'proof_time': '17-11-26 16:30',
 'speed': '7.976秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.52',
 'port': '8010',
 'proof_time': '17-11-26 16:30',
 'speed': '1.966秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏镇江',
 'alive_time': '144天',
 'ip': '180.118.241.123',
 'port': '808',
 'proof_time': '17-11-26 16:00',
 'speed': '0.427秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '620天',
 'ip': '110.73.0.127',
 'port': '8123',
 'proof_time': '17-11-26 16:00',
 'speed': '0.329秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏徐州',
 'alive_time': '153天',
 'ip': '180.124.188.50',
 'port': '808',
 'proof_time': '17-11-26 15:57',
 'speed': '0.198秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.220',
 'port': '8010',
 'proof_time': '17-11-26 15:55',
 'speed': '2.35秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏宿迁市泗阳县',
 'alive_time': '53天',
 'ip': '114.239.151.90',
 'port': '36572',
 'proof_time': '17-11-26 15:55',
 'speed': '0.557秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '115.202.235.45',
 'port': '41663',
 'proof_time': '17-11-26 15:45',
 'speed': '2.583秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江宁波',
 'alive_time': '231天',
 'ip': '115.217.255.153',
 'port': '808',
 'proof_time': '17-11-26 15:45',
 'speed': '5.572秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '218.73.130.89',
 'port': '39066',
 'proof_time': '17-11-26 15:45',
 'speed': '0.254秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '114.226.163.52',
 'port': '35598',
 'proof_time': '17-11-26 15:45',
 'speed': '0.228秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '222.187.166.237',
 'port': '25431',
 'proof_time': '17-11-26 15:45',
 'speed': '0.19秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.177.23',
 'port': '8123',
 'proof_time': '17-11-26 15:44',
 'speed': '2.127秒',
 'style': 'HTTPS'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西桂林',
 'alive_time': '655天',
 'ip': '121.31.193.203',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '3.247秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '3分钟',
 'ip': '110.72.23.44',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '0.987秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:14 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '2分钟',
 'ip': '182.88.129.91',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '0.276秒',
 'style': 'HTTP'}
2017-11-27 10:37:14 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '447天',
 'ip': '121.31.101.86',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '2.447秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '743天',
 'ip': '182.88.179.98',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '3.439秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '河南新乡',
 'alive_time': '1分钟',
 'ip': '123.55.89.195',
 'port': '37330',
 'proof_time': '17-11-26 15:33',
 'speed': '0.24秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '266天',
 'ip': '182.90.48.24',
 'port': '8123',
 'proof_time': '17-11-26 15:31',
 'speed': '4.723秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '519天',
 'ip': '121.31.101.38',
 'port': '8123',
 'proof_time': '17-11-26 15:31',
 'speed': '5.339秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '2小时',
 'ip': '223.241.119.15',
 'port': '8010',
 'proof_time': '17-11-26 15:31',
 'speed': '5.847秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '1分钟',
 'ip': '110.73.4.88',
 'port': '8123',
 'proof_time': '17-11-26 15:30',
 'speed': '7.944秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.127',
 'port': '8010',
 'proof_time': '17-11-26 15:22',
 'speed': '4.026秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.117.49',
 'port': '8010',
 'proof_time': '17-11-26 15:22',
 'speed': '3.079秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.31.210',
 'port': '8123',
 'proof_time': '17-11-26 15:22',
 'speed': '0.857秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '120.37.164.86',
 'port': '37783',
 'proof_time': '17-11-26 15:15',
 'speed': '0.183秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '5天',
 'ip': '223.241.79.160',
 'port': '8010',
 'proof_time': '17-11-26 15:00',
 'speed': '5.107秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.116.241',
 'port': '8010',
 'proof_time': '17-11-26 14:46',
 'speed': '5.248秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.119.127',
 'port': '8010',
 'proof_time': '17-11-26 14:44',
 'speed': '2.111秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '691天',
 'ip': '121.31.197.24',
 'port': '8123',
 'proof_time': '17-11-26 14:33',
 'speed': '6.529秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.33.204',
 'port': '8123',
 'proof_time': '17-11-26 14:22',
 'speed': '3.096秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '14天',
 'ip': '223.241.78.206',
 'port': '8010',
 'proof_time': '17-11-26 14:22',
 'speed': '6.24秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '7小时',
 'ip': '112.114.99.50',
 'port': '8118',
 'proof_time': '17-11-26 14:16',
 'speed': '0.329秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '10天',
 'ip': '223.241.117.85',
 'port': '8010',
 'proof_time': '17-11-26 14:15',
 'speed': '6.304秒',
 'style': 'HTTPS'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '121.31.81.102',
 'port': '8123',
 'proof_time': '17-11-26 14:15',
 'speed': '0.423秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '四川德阳',
 'alive_time': '1分钟',
 'ip': '110.189.207.39',
 'port': '48622',
 'proof_time': '17-11-26 14:15',
 'speed': '0.728秒',
 'style': 'HTTP'}
2017-11-27 10:37:15 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西',
 'alive_time': '102天',
 'ip': '171.108.205.85',
 'port': '53281',
 'proof_time': '17-11-26 14:15',
 'speed': '0.55秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '688天',
 'ip': '110.73.35.51',
 'port': '8123',
 'proof_time': '17-11-26 14:11',
 'speed': '1.264秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.45.159',
 'port': '8123',
 'proof_time': '17-11-26 14:00',
 'speed': '3.583秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '福建厦门',
 'alive_time': '2天',
 'ip': '120.32.208.19',
 'port': '8118',
 'proof_time': '17-11-26 14:00',
 'speed': '0.172秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.55.200.32',
 'port': '38406',
 'proof_time': '17-11-26 13:55',
 'speed': '0.305秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '49.81.10.118',
 'port': '46290',
 'proof_time': '17-11-26 13:55',
 'speed': '0.644秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏',
 'alive_time': '1分钟',
 'ip': '121.226.163.85',
 'port': '32181',
 'proof_time': '17-11-26 13:55',
 'speed': '0.164秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江温州',
 'alive_time': '6分钟',
 'ip': '218.73.134.89',
 'port': '49015',
 'proof_time': '17-11-26 13:50',
 'speed': '1.184秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江舟山',
 'alive_time': '1分钟',
 'ip': '115.209.179.186',
 'port': '37433',
 'proof_time': '17-11-26 13:46',
 'speed': '1.832秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江宁波',
 'alive_time': '27天',
 'ip': '115.217.253.77',
 'port': '30580',
 'proof_time': '17-11-26 13:46',
 'speed': '2.145秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.254.132',
 'port': '33222',
 'proof_time': '17-11-26 13:46',
 'speed': '0.199秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江丽水',
 'alive_time': '1分钟',
 'ip': '115.226.151.41',
 'port': '22042',
 'proof_time': '17-11-26 13:46',
 'speed': '2.174秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '634天',
 'ip': '110.73.1.23',
 'port': '8123',
 'proof_time': '17-11-26 13:33',
 'speed': '4.967秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '河南开封',
 'alive_time': '19小时',
 'ip': '123.163.137.56',
 'port': '808',
 'proof_time': '17-11-26 13:18',
 'speed': '0.119秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '121.231.144.19',
 'port': '6666',
 'proof_time': '17-11-26 13:16',
 'speed': '0.132秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '328天',
 'ip': '121.31.79.116',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '5.141秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '583天',
 'ip': '110.73.8.229',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '3.229秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.119.101',
 'port': '8010',
 'proof_time': '17-11-26 13:15',
 'speed': '4.57秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.76.45',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '1.934秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '327天',
 'ip': '110.73.7.140',
 'port': '8123',
 'proof_time': '17-11-26 13:11',
 'speed': '6.031秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '648天',
 'ip': '110.73.4.128',
 'port': '8123',
 'proof_time': '17-11-26 13:11',
 'speed': '6.114秒',
 'style': 'HTTP'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:16 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '17小时',
 'ip': '112.114.93.56',
 'port': '8118',
 'proof_time': '17-11-26 13:09',
 'speed': '0.418秒',
 'style': 'HTTPS'}
2017-11-27 10:37:16 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '6天',
 'ip': '223.241.119.13',
 'port': '8010',
 'proof_time': '17-11-26 13:00',
 'speed': '2.216秒',
 'style': 'HTTPS'}
2017-11-27 10:37:17 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '121.231.150.223',
 'port': '6666',
 'proof_time': '17-11-26 13:00',
 'speed': '0.149秒',
 'style': 'HTTPS'}
2017-11-27 10:37:17 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东佛山',
 'alive_time': '1分钟',
 'ip': '119.127.17.162',
 'port': '808',
 'proof_time': '17-11-26 13:00',
 'speed': '3.658秒',
 'style': 'HTTP'}
2017-11-27 10:37:17 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东佛山',
 'alive_time': '1分钟',
 'ip': '119.127.17.162',
 'port': '808',
 'proof_time': '17-11-26 13:00',
 'speed': '3.264秒',
 'style': 'HTTPS'}
2017-11-27 10:37:17 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:17 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东深圳',
 'alive_time': '4小时',
 'ip': '116.30.233.134',
 'port': '8118',
 'proof_time': '17-11-26 12:51',
 'speed': '0.255秒',
 'style': 'HTTP'}
2017-11-27 10:37:17 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:37:17 [scrapy.core.engine] INFO: Closing spider (finished)
2017-11-27 10:37:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1372,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 24994,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 200,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 11, 27, 2, 37, 17, 196046),
 'item_scraped_count': 300,
 'log_count/DEBUG': 406,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 11, 27, 2, 36, 48, 576017)}
2017-11-27 10:37:17 [scrapy.core.engine] INFO: Spider closed (finished)
2017-11-27 10:37:33 [scrapy.utils.log] INFO: Scrapy 1.4.0 started (bot: collectionips)
2017-11-27 10:37:33 [scrapy.utils.log] INFO: Overridden settings: {'BOT_NAME': 'collectionips', 'DEPTH_LIMIT': 2, 'DOWNLOAD_DELAY': 10, 'LOG_FILE': 'scrapy.log', 'NEWSPIDER_MODULE': 'collectionips.spiders', 'SPIDER_MODULES': ['collectionips.spiders'], 'USER_AGENT': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:57.0) Gecko/20100101 Firefox/57.0'}
2017-11-27 10:37:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2017-11-27 10:37:34 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2017-11-27 10:37:34 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2017-11-27 10:37:34 [py.warnings] WARNING: E:\scrapy_study\collectionips\collectionips\pipelines.py:11: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2017-11-27 10:37:34 [scrapy.middleware] INFO: Enabled item pipelines:
['collectionips.pipelines.CollectionipsPipeline',
 'collectionips.pipelines.MySQLPipeline']
2017-11-27 10:37:34 [scrapy.core.engine] INFO: Spider opened
2017-11-27 10:37:34 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2017-11-27 10:37:34 [scrapy.extensions.telnet] DEBUG: Telnet console listening on 127.0.0.1:6023
2017-11-27 10:37:34 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn> (referer: None)
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江杭州',
 'alive_time': '102天',
 'ip': '101.68.73.54',
 'port': '53281',
 'proof_time': '17-11-27 10:30',
 'speed': '0.218秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.dupefilters] DEBUG: Filtered duplicate request: <GET http://www.xicidaili.com/nn/2> - no more duplicates will be shown (see DUPEFILTER_DEBUG to show all duplicates)
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '656天',
 'ip': '110.73.55.126',
 'port': '8123',
 'proof_time': '17-11-27 10:30',
 'speed': '0.3秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '27天',
 'ip': '111.155.116.218',
 'port': '8123',
 'proof_time': '17-11-27 10:30',
 'speed': '1.063秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '辽宁大连',
 'alive_time': '8小时',
 'ip': '113.226.146.239',
 'port': '8080',
 'proof_time': '17-11-27 10:26',
 'speed': '0.104秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '辽宁葫芦岛',
 'alive_time': '3天',
 'ip': '123.56.86.187',
 'port': '3128',
 'proof_time': '17-11-27 10:26',
 'speed': '0.01秒',
 'style': 'HTTPS'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '10小时',
 'ip': '219.138.58.187',
 'port': '3128',
 'proof_time': '17-11-27 10:25',
 'speed': '0.834秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河南郑州',
 'alive_time': '8小时',
 'ip': '122.114.31.177',
 'port': '808',
 'proof_time': '17-11-27 10:24',
 'speed': '0.107秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '563天',
 'ip': '61.135.217.7',
 'port': '80',
 'proof_time': '17-11-27 10:24',
 'speed': '0.324秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '',
 'alive_time': '1天',
 'ip': '123.207.8.94',
 'port': '8080',
 'proof_time': '17-11-27 10:24',
 'speed': '0.178秒',
 'style': 'HTTPS'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江宁波',
 'alive_time': '2小时',
 'ip': '115.217.25.246',
 'port': '808',
 'proof_time': '17-11-27 10:23',
 'speed': '2.345秒',
 'style': 'HTTP'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '6小时',
 'ip': '221.233.85.141',
 'port': '3128',
 'proof_time': '17-11-27 10:22',
 'speed': '0.929秒',
 'style': 'HTTPS'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '118天',
 'ip': '112.114.95.56',
 'port': '8118',
 'proof_time': '17-11-27 10:22',
 'speed': '0.328秒',
 'style': 'HTTPS'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '114天',
 'ip': '112.114.96.164',
 'port': '8118',
 'proof_time': '17-11-27 10:18',
 'speed': '0.909秒',
 'style': 'HTTPS'}
2017-11-27 10:37:34 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏扬州',
 'alive_time': '1分钟',
 'ip': '114.230.127.127',
 'port': '23294',
 'proof_time': '17-11-27 10:16',
 'speed': '3.887秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.25.87',
 'port': '8123',
 'proof_time': '17-11-27 10:16',
 'speed': '4.339秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.20.6',
 'port': '8123',
 'proof_time': '17-11-27 10:15',
 'speed': '5.925秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '铁通',
 'alive_time': '1天',
 'ip': '110.216.60.136',
 'port': '80',
 'proof_time': '17-11-27 10:11',
 'speed': '0.347秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河北保定',
 'alive_time': '1分钟',
 'ip': '124.237.128.42',
 'port': '9999',
 'proof_time': '17-11-27 10:11',
 'speed': '0.154秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '182.88.187.217',
 'port': '8123',
 'proof_time': '17-11-27 10:11',
 'speed': '0.483秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.20',
 'port': '8010',
 'proof_time': '17-11-27 10:11',
 'speed': '6.217秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '86天',
 'ip': '110.72.17.204',
 'port': '8123',
 'proof_time': '17-11-27 10:11',
 'speed': '3.55秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '上海',
 'alive_time': '10小时',
 'ip': '180.175.120.96',
 'port': '51552',
 'proof_time': '17-11-27 10:10',
 'speed': '0.191秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '山西大同',
 'alive_time': '7小时',
 'ip': '118.72.124.97',
 'port': '80',
 'proof_time': '17-11-27 10:09',
 'speed': '0.098秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河南三门峡',
 'alive_time': '21小时',
 'ip': '123.55.190.127',
 'port': '30670',
 'proof_time': '17-11-27 10:04',
 'speed': '0.265秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建泉州',
 'alive_time': '13小时',
 'ip': '117.24.36.67',
 'port': '808',
 'proof_time': '17-11-27 10:03',
 'speed': '3.546秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建龙岩',
 'alive_time': '1分钟',
 'ip': '121.206.87.230',
 'port': '46046',
 'proof_time': '17-11-27 09:55',
 'speed': '0.24秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江杭州',
 'alive_time': '3天',
 'ip': '125.119.160.69',
 'port': '8118',
 'proof_time': '17-11-27 09:47',
 'speed': '2.334秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏镇江',
 'alive_time': '2分钟',
 'ip': '180.118.195.69',
 'port': '23959',
 'proof_time': '17-11-27 09:46',
 'speed': '0.54秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '5天',
 'ip': '219.138.58.59',
 'port': '3128',
 'proof_time': '17-11-27 09:45',
 'speed': '1.237秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广东东莞',
 'alive_time': '1小时',
 'ip': '113.79.74.68',
 'port': '808',
 'proof_time': '17-11-27 09:42',
 'speed': '0.224秒',
 'style': 'HTTPS'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '484天',
 'ip': '110.72.22.61',
 'port': '8123',
 'proof_time': '17-11-27 09:41',
 'speed': '0.575秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '31天',
 'ip': '120.25.164.134',
 'port': '8118',
 'proof_time': '17-11-27 09:34',
 'speed': '0.239秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '230天',
 'ip': '111.155.116.215',
 'port': '8123',
 'proof_time': '17-11-27 09:22',
 'speed': '1.808秒',
 'style': 'HTTP'}
2017-11-27 10:37:35 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '119天',
 'ip': '111.155.116.232',
 'port': '8123',
 'proof_time': '17-11-27 09:21',
 'speed': '2.736秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '100天',
 'ip': '112.114.95.59',
 'port': '8118',
 'proof_time': '17-11-27 09:19',
 'speed': '0.363秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '12小时',
 'ip': '219.138.58.33',
 'port': '3128',
 'proof_time': '17-11-27 09:14',
 'speed': '0.693秒',
 'style': 'HTTP'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江绍兴',
 'alive_time': '7小时',
 'ip': '183.144.192.184',
 'port': '3128',
 'proof_time': '17-11-27 09:12',
 'speed': '0.417秒',
 'style': 'HTTP'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '四川泸州',
 'alive_time': '13天',
 'ip': '218.88.215.109',
 'port': '8118',
 'proof_time': '17-11-27 09:10',
 'speed': '0.263秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江西',
 'alive_time': '7天',
 'ip': '171.35.103.37',
 'port': '808',
 'proof_time': '17-11-27 09:09',
 'speed': '0.196秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.99.227',
 'port': '8118',
 'proof_time': '17-11-27 09:01',
 'speed': '0.343秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '山东日照',
 'alive_time': '5小时',
 'ip': '182.37.117.26',
 'port': '808',
 'proof_time': '17-11-27 08:53',
 'speed': '0.169秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '上海',
 'alive_time': '2天',
 'ip': '58.246.123.42',
 'port': '808',
 'proof_time': '17-11-27 08:53',
 'speed': '0.144秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.97.127',
 'port': '8118',
 'proof_time': '17-11-27 08:51',
 'speed': '0.32秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.252.150',
 'port': '29745',
 'proof_time': '17-11-27 08:46',
 'speed': '0.171秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '22小时',
 'ip': '223.241.119.208',
 'port': '8010',
 'proof_time': '17-11-27 08:46',
 'speed': '7.188秒',
 'style': 'HTTP'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '山东济南',
 'alive_time': '2分钟',
 'ip': '122.4.43.19',
 'port': '42331',
 'proof_time': '17-11-27 08:46',
 'speed': '0.132秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江丽水',
 'alive_time': '2分钟',
 'ip': '115.213.206.220',
 'port': '33904',
 'proof_time': '17-11-27 08:46',
 'speed': '1.251秒',
 'style': 'HTTPS'}
2017-11-27 10:37:36 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江',
 'alive_time': '1分钟',
 'ip': '36.25.111.118',
 'port': '40064',
 'proof_time': '17-11-27 08:45',
 'speed': '0.144秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '483天',
 'ip': '182.88.44.116',
 'port': '8123',
 'proof_time': '17-11-27 08:45',
 'speed': '7.174秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '7天',
 'ip': '223.241.79.224',
 'port': '8010',
 'proof_time': '17-11-27 08:44',
 'speed': '2.11秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.243',
 'port': '8010',
 'proof_time': '17-11-27 08:44',
 'speed': '2.548秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '黑龙江哈尔滨',
 'alive_time': '100天',
 'ip': '125.211.202.26',
 'port': '53281',
 'proof_time': '17-11-27 08:39',
 'speed': '2.836秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建福州',
 'alive_time': '7分钟',
 'ip': '27.156.215.117',
 'port': '39382',
 'proof_time': '17-11-27 08:30',
 'speed': '0.197秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西贵港',
 'alive_time': '1小时',
 'ip': '110.72.17.11',
 'port': '8123',
 'proof_time': '17-11-27 08:30',
 'speed': '2.125秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏南通',
 'alive_time': '1分钟',
 'ip': '117.86.204.52',
 'port': '28488',
 'proof_time': '17-11-27 08:22',
 'speed': '0.147秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '29天',
 'ip': '223.241.78.85',
 'port': '8010',
 'proof_time': '17-11-27 08:22',
 'speed': '1.931秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江舟山',
 'alive_time': '6分钟',
 'ip': '123.96.0.101',
 'port': '33042',
 'proof_time': '17-11-27 08:22',
 'speed': '0.26秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西玉林',
 'alive_time': '713天',
 'ip': '171.38.85.125',
 'port': '8123',
 'proof_time': '17-11-27 08:22',
 'speed': '1.077秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏南通',
 'alive_time': '6分钟',
 'ip': '117.86.166.92',
 'port': '20638',
 'proof_time': '17-11-27 08:21',
 'speed': '0.173秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏泰州',
 'alive_time': '1分钟',
 'ip': '180.122.149.206',
 'port': '24295',
 'proof_time': '17-11-27 08:15',
 'speed': '0.153秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '218.81.237.58',
 'port': '22624',
 'proof_time': '17-11-27 08:15',
 'speed': '0.127秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广东茂名',
 'alive_time': '6小时',
 'ip': '113.94.76.14',
 'port': '3128',
 'proof_time': '17-11-27 08:11',
 'speed': '0.2秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '1小时',
 'ip': '221.233.85.110',
 'port': '3128',
 'proof_time': '17-11-27 08:09',
 'speed': '0.71秒',
 'style': 'HTTPS'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '19分钟',
 'ip': '219.138.58.202',
 'port': '3128',
 'proof_time': '17-11-27 08:04',
 'speed': '0.782秒',
 'style': 'HTTP'}
2017-11-27 10:37:37 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '四川成都',
 'alive_time': '674天',
 'ip': '118.114.77.47',
 'port': '8080',
 'proof_time': '17-11-27 08:01',
 'speed': '3.136秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '17天',
 'ip': '223.241.116.220',
 'port': '8010',
 'proof_time': '17-11-27 07:55',
 'speed': '5.715秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '11小时',
 'ip': '223.241.118.214',
 'port': '8010',
 'proof_time': '17-11-27 07:55',
 'speed': '6.703秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.76.5',
 'port': '8123',
 'proof_time': '17-11-27 07:45',
 'speed': '4.871秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建厦门',
 'alive_time': '357天',
 'ip': '121.204.165.246',
 'port': '8118',
 'proof_time': '17-11-27 07:40',
 'speed': '0.179秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '98天',
 'ip': '118.187.58.34',
 'port': '53281',
 'proof_time': '17-11-27 07:35',
 'speed': '1.137秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.99.147',
 'port': '8123',
 'proof_time': '17-11-27 07:31',
 'speed': '5.513秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.120.40',
 'port': '8123',
 'proof_time': '17-11-27 07:31',
 'speed': '0.328秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏',
 'alive_time': '1分钟',
 'ip': '117.62.177.126',
 'port': '8118',
 'proof_time': '17-11-27 07:22',
 'speed': '4.886秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '34天',
 'ip': '223.241.79.7',
 'port': '8010',
 'proof_time': '17-11-27 07:22',
 'speed': '5.675秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '湖北襄阳',
 'alive_time': '5小时',
 'ip': '221.233.85.235',
 'port': '3128',
 'proof_time': '17-11-27 07:22',
 'speed': '1.231秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江台州',
 'alive_time': '10小时',
 'ip': '115.203.221.178',
 'port': '8888',
 'proof_time': '17-11-27 07:21',
 'speed': '0.859秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1119天',
 'ip': '60.169.78.218',
 'port': '808',
 'proof_time': '17-11-27 07:21',
 'speed': '2.68秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏无锡',
 'alive_time': '1分钟',
 'ip': '114.224.85.225',
 'port': '38954',
 'proof_time': '17-11-27 06:55',
 'speed': '1.259秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '222.79.178.83',
 'port': '45956',
 'proof_time': '17-11-27 06:55',
 'speed': '0.184秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江丽水',
 'alive_time': '1分钟',
 'ip': '115.230.79.93',
 'port': '46297',
 'proof_time': '17-11-27 06:55',
 'speed': '1.76秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建福州',
 'alive_time': '1分钟',
 'ip': '27.156.195.189',
 'port': '40298',
 'proof_time': '17-11-27 06:55',
 'speed': '1.659秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '北京',
 'alive_time': '433天',
 'ip': '202.108.2.42',
 'port': '80',
 'proof_time': '17-11-27 06:39',
 'speed': '5.855秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江杭州',
 'alive_time': '229天',
 'ip': '125.120.40.65',
 'port': '808',
 'proof_time': '17-11-27 06:33',
 'speed': '4.099秒',
 'style': 'HTTPS'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.119.63',
 'port': '8010',
 'proof_time': '17-11-27 06:31',
 'speed': '7.536秒',
 'style': 'HTTP'}
2017-11-27 10:37:38 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.91',
 'port': '8010',
 'proof_time': '17-11-27 06:22',
 'speed': '2.714秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '吉林四平',
 'alive_time': '4小时',
 'ip': '122.143.142.25',
 'port': '80',
 'proof_time': '17-11-27 06:17',
 'speed': '0.103秒',
 'style': 'HTTP'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.122',
 'port': '8010',
 'proof_time': '17-11-27 06:15',
 'speed': '1.954秒',
 'style': 'HTTP'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '5天',
 'ip': '223.241.119.198',
 'port': '8010',
 'proof_time': '17-11-27 06:01',
 'speed': '0.52秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '60天',
 'ip': '223.241.116.35',
 'port': '8010',
 'proof_time': '17-11-27 05:55',
 'speed': '5.749秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '36.7.58.8',
 'port': '49151',
 'proof_time': '17-11-27 05:44',
 'speed': '5.252秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '121.205.11.189',
 'port': '29970',
 'proof_time': '17-11-27 05:44',
 'speed': '0.183秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江嘉兴',
 'alive_time': '3分钟',
 'ip': '122.231.32.27',
 'port': '24567',
 'proof_time': '17-11-27 05:33',
 'speed': '0.605秒',
 'style': 'HTTP'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '114.228.75.179',
 'port': '53650',
 'proof_time': '17-11-27 05:30',
 'speed': '1.897秒',
 'style': 'HTTP'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '广东广州',
 'alive_time': '101天',
 'ip': '183.63.140.82',
 'port': '53281',
 'proof_time': '17-11-27 05:22',
 'speed': '0.258秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '河南平顶山',
 'alive_time': '1分钟',
 'ip': '123.161.237.255',
 'port': '47565',
 'proof_time': '17-11-27 05:22',
 'speed': '0.13秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.215.51.161',
 'port': '42517',
 'proof_time': '17-11-27 05:22',
 'speed': '0.175秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '江苏常州',
 'alive_time': '6分钟',
 'ip': '218.93.105.98',
 'port': '40260',
 'proof_time': '17-11-27 05:21',
 'speed': '6.653秒',
 'style': 'HTTP'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '天津',
 'alive_time': '1分钟',
 'ip': '180.213.173.19',
 'port': '8123',
 'proof_time': '17-11-27 05:11',
 'speed': '5.964秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.223',
 'port': '8010',
 'proof_time': '17-11-27 05:11',
 'speed': '2.156秒',
 'style': 'HTTPS'}
2017-11-27 10:37:39 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn>
{'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.177.143.109',
 'port': '49715',
 'proof_time': '17-11-27 04:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
2017-11-27 10:37:47 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/2> (referer: http://www.xicidaili.com/nn)
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.177.143.109',
 'port': '49715',
 'proof_time': '17-11-27 04:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '115.221.117.198',
 'port': '35483',
 'proof_time': '17-11-27 04:55',
 'speed': '0.597秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏淮安',
 'alive_time': '1分钟',
 'ip': '49.87.218.243',
 'port': '36887',
 'proof_time': '17-11-27 04:55',
 'speed': '3.952秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '甘肃兰州市城关区',
 'alive_time': '633天',
 'ip': '61.178.238.122',
 'port': '63000',
 'proof_time': '17-11-27 04:41',
 'speed': '0.338秒',
 'style': 'HTTP'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '18天',
 'ip': '223.241.118.61',
 'port': '8010',
 'proof_time': '17-11-27 04:31',
 'speed': '2.004秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.121',
 'port': '8010',
 'proof_time': '17-11-27 04:31',
 'speed': '0.565秒',
 'style': 'HTTP'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.78.19',
 'port': '8010',
 'proof_time': '17-11-27 04:11',
 'speed': '7.059秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.93',
 'port': '8010',
 'proof_time': '17-11-27 04:11',
 'speed': '3.515秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.67.22',
 'port': '8123',
 'proof_time': '17-11-27 03:55',
 'speed': '3.294秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '125.112.195.191',
 'port': '46118',
 'proof_time': '17-11-27 03:55',
 'speed': '0.509秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '河南平顶山',
 'alive_time': '214天',
 'ip': '222.85.39.20',
 'port': '808',
 'proof_time': '17-11-27 03:55',
 'speed': '1.005秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '222.71.89.136',
 'port': '46443',
 'proof_time': '17-11-27 03:55',
 'speed': '0.126秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '黑龙江',
 'alive_time': '1分钟',
 'ip': '116.62.217.206',
 'port': '80',
 'proof_time': '17-11-27 03:46',
 'speed': '2.201秒',
 'style': 'HTTP'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.254.247',
 'port': '39426',
 'proof_time': '17-11-27 03:46',
 'speed': '0.162秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '',
 'alive_time': '2天',
 'ip': '106.42.97.33',
 'port': '808',
 'proof_time': '17-11-27 03:30',
 'speed': '3.181秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '1天',
 'ip': '183.172.232.222',
 'port': '8118',
 'proof_time': '17-11-27 03:01',
 'speed': '0.145秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '河北保定',
 'alive_time': '1分钟',
 'ip': '124.237.128.148',
 'port': '9999',
 'proof_time': '17-11-27 03:00',
 'speed': '0.111秒',
 'style': 'HTTPS'}
2017-11-27 10:37:48 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.138.77',
 'port': '8123',
 'proof_time': '17-11-27 03:00',
 'speed': '4.072秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏苏州',
 'alive_time': '1分钟',
 'ip': '222.93.241.22',
 'port': '25206',
 'proof_time': '17-11-27 02:46',
 'speed': '3.017秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.28.161',
 'port': '8123',
 'proof_time': '17-11-27 02:45',
 'speed': '3.304秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '114.234.82.2',
 'port': '36847',
 'proof_time': '17-11-27 02:45',
 'speed': '3.926秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '2分钟',
 'ip': '182.88.179.176',
 'port': '8123',
 'proof_time': '17-11-27 02:33',
 'speed': '4.206秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '陕西渭南',
 'alive_time': '105天',
 'ip': '124.89.33.59',
 'port': '53281',
 'proof_time': '17-11-27 02:31',
 'speed': '0.11秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广东东莞',
 'alive_time': '3小时',
 'ip': '113.77.100.84',
 'port': '3128',
 'proof_time': '17-11-27 02:16',
 'speed': '0.471秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '125.109.197.191',
 'port': '29717',
 'proof_time': '17-11-27 02:16',
 'speed': '0.513秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '382天',
 'ip': '110.73.54.218',
 'port': '8123',
 'proof_time': '17-11-27 02:16',
 'speed': '4.395秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '708天',
 'ip': '121.31.79.243',
 'port': '8123',
 'proof_time': '17-11-27 02:16',
 'speed': '7.653秒',
 'style': 'HTTP'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '4分钟',
 'ip': '110.73.30.100',
 'port': '8123',
 'proof_time': '17-11-27 02:15',
 'speed': '2.91秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.50.90',
 'port': '8123',
 'proof_time': '17-11-27 02:11',
 'speed': '1.482秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '104天',
 'ip': '110.73.30.197',
 'port': '8123',
 'proof_time': '17-11-27 02:11',
 'speed': '3.901秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '云南临沧',
 'alive_time': '1小时',
 'ip': '112.114.79.182',
 'port': '8118',
 'proof_time': '17-11-27 02:09',
 'speed': '0.325秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.71.165',
 'port': '8123',
 'proof_time': '17-11-27 02:01',
 'speed': '2.833秒',
 'style': 'HTTPS'}
2017-11-27 10:37:49 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西',
 'alive_time': '1分钟',
 'ip': '171.37.171.1',
 'port': '8123',
 'proof_time': '17-11-27 02:00',
 'speed': '0.365秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '552天',
 'ip': '182.90.69.230',
 'port': '8123',
 'proof_time': '17-11-27 01:56',
 'speed': '6.033秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西玉林',
 'alive_time': '1分钟',
 'ip': '171.38.42.238',
 'port': '8123',
 'proof_time': '17-11-27 01:55',
 'speed': '5.622秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西玉林',
 'alive_time': '1分钟',
 'ip': '171.38.65.81',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.276秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西北海',
 'alive_time': '642天',
 'ip': '121.31.144.228',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.354秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.27.175',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '3.756秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '548天',
 'ip': '110.73.55.185',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '4.399秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.79.125',
 'port': '8123',
 'proof_time': '17-11-27 01:45',
 'speed': '0.262秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.54.115',
 'port': '8123',
 'proof_time': '17-11-27 01:44',
 'speed': '6.044秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '136天',
 'ip': '61.135.155.82',
 'port': '443',
 'proof_time': '17-11-27 01:33',
 'speed': '3.462秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.117.5',
 'port': '8010',
 'proof_time': '17-11-27 01:31',
 'speed': '0.79秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '4分钟',
 'ip': '223.241.116.27',
 'port': '8010',
 'proof_time': '17-11-27 01:15',
 'speed': '2.437秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '54天',
 'ip': '115.46.69.28',
 'port': '8123',
 'proof_time': '17-11-27 01:11',
 'speed': '5.763秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '铁通',
 'alive_time': '46天',
 'ip': '114.115.216.99',
 'port': '80',
 'proof_time': '17-11-27 01:08',
 'speed': '0.045秒',
 'style': 'HTTP'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '19天',
 'ip': '223.241.116.88',
 'port': '8010',
 'proof_time': '17-11-27 00:55',
 'speed': '0.694秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '四川德阳',
 'alive_time': '1分钟',
 'ip': '110.189.207.224',
 'port': '37695',
 'proof_time': '17-11-27 00:55',
 'speed': '2.267秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '60.169.216.165',
 'port': '44800',
 'proof_time': '17-11-27 00:55',
 'speed': '0.176秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.219.222',
 'port': '32022',
 'proof_time': '17-11-27 00:55',
 'speed': '0.606秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '114.234.82.127',
 'port': '33375',
 'proof_time': '17-11-27 00:44',
 'speed': '3.91秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.88.181',
 'port': '32473',
 'proof_time': '17-11-27 00:44',
 'speed': '5.954秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东济南',
 'alive_time': '1分钟',
 'ip': '122.4.47.99',
 'port': '38981',
 'proof_time': '17-11-27 00:44',
 'speed': '4.461秒',
 'style': 'HTTPS'}
2017-11-27 10:37:50 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东枣庄',
 'alive_time': '774天',
 'ip': '60.214.118.170',
 'port': '63000',
 'proof_time': '17-11-27 00:42',
 'speed': '0.218秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '吉林长春',
 'alive_time': '1小时',
 'ip': '123.173.81.190',
 'port': '80',
 'proof_time': '17-11-27 00:40',
 'speed': '1.406秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '吉林长春',
 'alive_time': '11小时',
 'ip': '58.244.59.208',
 'port': '8080',
 'proof_time': '17-11-27 00:31',
 'speed': '0.088秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '115.202.251.191',
 'port': '34648',
 'proof_time': '17-11-27 00:00',
 'speed': '1.44秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.142',
 'port': '8010',
 'proof_time': '17-11-27 00:00',
 'speed': '2.319秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '510天',
 'ip': '110.73.13.220',
 'port': '8123',
 'proof_time': '17-11-26 23:46',
 'speed': '1.385秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽芜湖',
 'alive_time': '8天',
 'ip': '223.241.78.159',
 'port': '8010',
 'proof_time': '17-11-26 23:45',
 'speed': '7.697秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北襄阳',
 'alive_time': '9小时',
 'ip': '221.233.85.178',
 'port': '3128',
 'proof_time': '17-11-26 23:34',
 'speed': '0.219秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '1分钟',
 'ip': '110.73.12.87',
 'port': '8123',
 'proof_time': '17-11-26 23:33',
 'speed': '7.033秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北襄阳',
 'alive_time': '2天',
 'ip': '219.138.58.245',
 'port': '3128',
 'proof_time': '17-11-26 23:33',
 'speed': '2.737秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.40.30',
 'port': '8123',
 'proof_time': '17-11-26 23:22',
 'speed': '0.574秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江舟山',
 'alive_time': '1分钟',
 'ip': '123.96.4.221',
 'port': '49466',
 'proof_time': '17-11-26 23:22',
 'speed': '1.158秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '福建龙岩',
 'alive_time': '1分钟',
 'ip': '59.58.242.45',
 'port': '38785',
 'proof_time': '17-11-26 23:16',
 'speed': '0.335秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏淮安',
 'alive_time': '1分钟',
 'ip': '49.87.176.128',
 'port': '42125',
 'proof_time': '17-11-26 23:16',
 'speed': '0.72秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '49.81.35.215',
 'port': '38349',
 'proof_time': '17-11-26 23:16',
 'speed': '2.751秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '云南临沧',
 'alive_time': '108天',
 'ip': '112.114.98.197',
 'port': '8118',
 'proof_time': '17-11-26 22:56',
 'speed': '1.831秒',
 'style': 'HTTP'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '江苏无锡',
 'alive_time': '1分钟',
 'ip': '222.191.169.153',
 'port': '49616',
 'proof_time': '17-11-26 22:55',
 'speed': '1.47秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '60.169.217.210',
 'port': '42112',
 'proof_time': '17-11-26 22:55',
 'speed': '0.692秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '安徽宿州',
 'alive_time': '1分钟',
 'ip': '60.175.197.108',
 'port': '49585',
 'proof_time': '17-11-26 22:55',
 'speed': '0.153秒',
 'style': 'HTTPS'}
2017-11-27 10:37:51 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '28分钟',
 'ip': '120.24.217.220',
 'port': '8080',
 'proof_time': '17-11-26 22:24',
 'speed': '0.149秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '715天',
 'ip': '110.73.52.184',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '6.448秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.110.75',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '7.749秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '25天',
 'ip': '121.31.100.168',
 'port': '8123',
 'proof_time': '17-11-26 22:16',
 'speed': '6.172秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '729天',
 'ip': '110.73.7.113',
 'port': '8123',
 'proof_time': '17-11-26 22:11',
 'speed': '3.722秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '40分钟',
 'ip': '110.73.31.159',
 'port': '8123',
 'proof_time': '17-11-26 21:55',
 'speed': '3.117秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西',
 'alive_time': '1分钟',
 'ip': '171.37.192.121',
 'port': '8123',
 'proof_time': '17-11-26 21:55',
 'speed': '4.771秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '41分钟',
 'ip': '115.46.97.171',
 'port': '8123',
 'proof_time': '17-11-26 21:52',
 'speed': '2.297秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '河南',
 'alive_time': '185天',
 'ip': '171.13.37.14',
 'port': '808',
 'proof_time': '17-11-26 21:46',
 'speed': '1.817秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '110.73.53.95',
 'port': '8123',
 'proof_time': '17-11-26 21:44',
 'speed': '4.227秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '',
 'alive_time': '12天',
 'ip': '106.14.241.155',
 'port': '80',
 'proof_time': '17-11-26 21:33',
 'speed': '0.117秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西贵港',
 'alive_time': '751天',
 'ip': '110.72.45.82',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '4.145秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西百色',
 'alive_time': '1分钟',
 'ip': '171.39.29.43',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '2.169秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北武汉',
 'alive_time': '1分钟',
 'ip': '27.19.48.74',
 'port': '8123',
 'proof_time': '17-11-26 21:30',
 'speed': '0.121秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '60.179.41.175',
 'port': '35037',
 'proof_time': '17-11-26 21:22',
 'speed': '0.242秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '333天',
 'ip': '110.73.3.86',
 'port': '8123',
 'proof_time': '17-11-26 21:22',
 'speed': '4.002秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西南宁',
 'alive_time': '585天',
 'ip': '110.73.51.71',
 'port': '8123',
 'proof_time': '17-11-26 21:15',
 'speed': '7.563秒',
 'style': 'HTTP'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '北京',
 'alive_time': '7天',
 'ip': '183.172.129.26',
 'port': '8118',
 'proof_time': '17-11-26 21:11',
 'speed': '1.801秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西',
 'alive_time': '23分钟',
 'ip': '171.39.236.9',
 'port': '8123',
 'proof_time': '17-11-26 20:45',
 'speed': '0.326秒',
 'style': 'HTTPS'}
2017-11-27 10:37:52 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '海南三亚',
 'alive_time': '4小时',
 'ip': '119.41.200.20',
 'port': '53281',
 'proof_time': '17-11-26 20:38',
 'speed': '0.909秒',
 'style': 'HTTPS'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '湖北襄阳',
 'alive_time': '1天',
 'ip': '221.233.85.31',
 'port': '3128',
 'proof_time': '17-11-26 20:36',
 'speed': '1.007秒',
 'style': 'HTTP'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '22分钟',
 'ip': '182.90.109.142',
 'port': '8123',
 'proof_time': '17-11-26 20:33',
 'speed': '2.767秒',
 'style': 'HTTPS'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西防城港',
 'alive_time': '752天',
 'ip': '121.31.101.158',
 'port': '8123',
 'proof_time': '17-11-26 20:33',
 'speed': '0.655秒',
 'style': 'HTTP'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西梧州',
 'alive_time': '19分钟',
 'ip': '182.90.69.228',
 'port': '8123',
 'proof_time': '17-11-26 20:30',
 'speed': '7.806秒',
 'style': 'HTTPS'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东济南',
 'alive_time': '1分钟',
 'ip': '122.4.45.172',
 'port': '49759',
 'proof_time': '17-11-26 20:16',
 'speed': '3.61秒',
 'style': 'HTTP'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.176.190',
 'port': '8123',
 'proof_time': '17-11-26 20:15',
 'speed': '0.77秒',
 'style': 'HTTP'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '广东江门',
 'alive_time': '1分钟',
 'ip': '61.143.16.165',
 'port': '24962',
 'proof_time': '17-11-26 20:15',
 'speed': '0.19秒',
 'style': 'HTTP'}
2017-11-27 10:37:53 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/2>
{'addrs': '山东',
 'alive_time': '1分钟',
 'ip': '140.250.135.166',
 'port': '44114',
 'proof_time': '17-11-26 20:15',
 'speed': '1.811秒',
 'style': 'HTTP'}
2017-11-27 10:38:02 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://www.xicidaili.com/nn/3> (referer: http://www.xicidaili.com/nn/2)
2017-11-27 10:38:02 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏苏州',
 'alive_time': '1分钟',
 'ip': '49.72.71.95',
 'port': '808',
 'proof_time': '17-11-26 20:11',
 'speed': '1.405秒',
 'style': 'HTTPS'}
2017-11-27 10:38:02 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '688天',
 'ip': '110.72.33.211',
 'port': '8123',
 'proof_time': '17-11-26 20:11',
 'speed': '7.743秒',
 'style': 'HTTP'}
2017-11-27 10:38:02 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:02 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '30天',
 'ip': '121.31.140.60',
 'port': '8123',
 'proof_time': '17-11-26 20:00',
 'speed': '5.223秒',
 'style': 'HTTP'}
2017-11-27 10:38:02 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '122天',
 'ip': '112.114.99.145',
 'port': '8118',
 'proof_time': '17-11-26 20:00',
 'speed': '1.34秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '183.149.226.254',
 'port': '37914',
 'proof_time': '17-11-26 19:55',
 'speed': '0.647秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '541天',
 'ip': '110.73.34.18',
 'port': '8123',
 'proof_time': '17-11-26 19:55',
 'speed': '3.49秒',
 'style': 'HTTP'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东江门市新会区',
 'alive_time': '6分钟',
 'ip': '218.14.141.184',
 'port': '49910',
 'proof_time': '17-11-26 19:50',
 'speed': '0.221秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '1天',
 'ip': '223.241.78.144',
 'port': '8010',
 'proof_time': '17-11-26 19:46',
 'speed': '1.993秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '122.242.90.87',
 'port': '29283',
 'proof_time': '17-11-26 19:45',
 'speed': '1.998秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '四川内江',
 'alive_time': '763天',
 'ip': '221.10.159.234',
 'port': '1337',
 'proof_time': '17-11-26 19:28',
 'speed': '0.447秒',
 'style': 'HTTP'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '2天',
 'ip': '223.241.116.149',
 'port': '8010',
 'proof_time': '17-11-26 19:15',
 'speed': '6.221秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏盐城',
 'alive_time': '16分钟',
 'ip': '121.234.118.67',
 'port': '23447',
 'proof_time': '17-11-26 19:01',
 'speed': '0.507秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '湖北襄阳',
 'alive_time': '4天',
 'ip': '219.138.58.52',
 'port': '3128',
 'proof_time': '17-11-26 18:55',
 'speed': '1.851秒',
 'style': 'HTTPS'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '10小时',
 'ip': '112.114.99.84',
 'port': '8118',
 'proof_time': '17-11-26 18:52',
 'speed': '0.373秒',
 'style': 'HTTP'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:03 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '31分钟',
 'ip': '223.241.117.122',
 'port': '8010',
 'proof_time': '17-11-26 18:47',
 'speed': '7.525秒',
 'style': 'HTTP'}
2017-11-27 10:38:03 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.119.167',
 'port': '8010',
 'proof_time': '17-11-26 18:33',
 'speed': '3.232秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '上海',
 'alive_time': '1分钟',
 'ip': '180.155.139.172',
 'port': '21494',
 'proof_time': '17-11-26 18:33',
 'speed': '0.161秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '12小时',
 'ip': '121.231.226.177',
 'port': '6666',
 'proof_time': '17-11-26 18:31',
 'speed': '0.387秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江金华',
 'alive_time': '1分钟',
 'ip': '125.112.194.167',
 'port': '40133',
 'proof_time': '17-11-26 18:16',
 'speed': '1.514秒',
 'style': 'HTTP'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '182.90.105.86',
 'port': '8123',
 'proof_time': '17-11-26 18:15',
 'speed': '7.984秒',
 'style': 'HTTP'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '湖北襄阳',
 'alive_time': '114天',
 'ip': '219.138.58.119',
 'port': '3128',
 'proof_time': '17-11-26 18:14',
 'speed': '1.06秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '山东济宁',
 'alive_time': '8小时',
 'ip': '113.120.183.26',
 'port': '808',
 'proof_time': '17-11-26 17:33',
 'speed': '0.109秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '8天',
 'ip': '223.241.117.137',
 'port': '8010',
 'proof_time': '17-11-26 17:30',
 'speed': '1.701秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东深圳',
 'alive_time': '23小时',
 'ip': '116.25.251.21',
 'port': '8088',
 'proof_time': '17-11-26 17:24',
 'speed': '6.221秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '2小时',
 'ip': '223.241.117.2',
 'port': '8010',
 'proof_time': '17-11-26 17:11',
 'speed': '6.832秒',
 'style': 'HTTP'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '北京',
 'alive_time': '1分钟',
 'ip': '183.172.178.147',
 'port': '8118',
 'proof_time': '17-11-26 17:11',
 'speed': '0.17秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:04 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏镇江',
 'alive_time': '11小时',
 'ip': '180.118.243.24',
 'port': '61234',
 'proof_time': '17-11-26 17:10',
 'speed': '5.475秒',
 'style': 'HTTPS'}
2017-11-27 10:38:04 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '福建莆田',
 'alive_time': '1分钟',
 'ip': '110.85.89.213',
 'port': '44033',
 'proof_time': '17-11-26 16:55',
 'speed': '2.106秒',
 'style': 'HTTPS'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '湖北襄阳',
 'alive_time': '4天',
 'ip': '219.138.58.143',
 'port': '3128',
 'proof_time': '17-11-26 16:54',
 'speed': '0.979秒',
 'style': 'HTTPS'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '河南开封',
 'alive_time': '1分钟',
 'ip': '123.55.157.112',
 'port': '808',
 'proof_time': '17-11-26 16:45',
 'speed': '0.113秒',
 'style': 'HTTPS'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '3小时',
 'ip': '223.241.78.218',
 'port': '8010',
 'proof_time': '17-11-26 16:45',
 'speed': '2.857秒',
 'style': 'HTTP'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '14分钟',
 'ip': '182.90.106.250',
 'port': '8123',
 'proof_time': '17-11-26 16:44',
 'speed': '0.32秒',
 'style': 'HTTP'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '8天',
 'ip': '223.241.119.221',
 'port': '8010',
 'proof_time': '17-11-26 16:33',
 'speed': '2.378秒',
 'style': 'HTTPS'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '488天',
 'ip': '110.73.55.76',
 'port': '8123',
 'proof_time': '17-11-26 16:33',
 'speed': '5.859秒',
 'style': 'HTTP'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.173.215',
 'port': '8123',
 'proof_time': '17-11-26 16:33',
 'speed': '0.372秒',
 'style': 'HTTPS'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:05 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '78天',
 'ip': '110.73.49.124',
 'port': '8123',
 'proof_time': '17-11-26 16:30',
 'speed': '6.021秒',
 'style': 'HTTPS'}
2017-11-27 10:38:05 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '天津',
 'alive_time': '59分钟',
 'ip': '180.213.192.104',
 'port': '8123',
 'proof_time': '17-11-26 16:30',
 'speed': '7.976秒',
 'style': 'HTTP'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.116.52',
 'port': '8010',
 'proof_time': '17-11-26 16:30',
 'speed': '1.966秒',
 'style': 'HTTP'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏镇江',
 'alive_time': '144天',
 'ip': '180.118.241.123',
 'port': '808',
 'proof_time': '17-11-26 16:00',
 'speed': '0.427秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '620天',
 'ip': '110.73.0.127',
 'port': '8123',
 'proof_time': '17-11-26 16:00',
 'speed': '0.329秒',
 'style': 'HTTP'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏徐州',
 'alive_time': '153天',
 'ip': '180.124.188.50',
 'port': '808',
 'proof_time': '17-11-26 15:57',
 'speed': '0.198秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.118.220',
 'port': '8010',
 'proof_time': '17-11-26 15:55',
 'speed': '2.35秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏宿迁市泗阳县',
 'alive_time': '53天',
 'ip': '114.239.151.90',
 'port': '36572',
 'proof_time': '17-11-26 15:55',
 'speed': '0.557秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江台州',
 'alive_time': '1分钟',
 'ip': '115.202.235.45',
 'port': '41663',
 'proof_time': '17-11-26 15:45',
 'speed': '2.583秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江宁波',
 'alive_time': '231天',
 'ip': '115.217.255.153',
 'port': '808',
 'proof_time': '17-11-26 15:45',
 'speed': '5.572秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江温州',
 'alive_time': '1分钟',
 'ip': '218.73.130.89',
 'port': '39066',
 'proof_time': '17-11-26 15:45',
 'speed': '0.254秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '114.226.163.52',
 'port': '35598',
 'proof_time': '17-11-26 15:45',
 'speed': '0.228秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:06 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '222.187.166.237',
 'port': '25431',
 'proof_time': '17-11-26 15:45',
 'speed': '0.19秒',
 'style': 'HTTPS'}
2017-11-27 10:38:06 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '1分钟',
 'ip': '121.31.177.23',
 'port': '8123',
 'proof_time': '17-11-26 15:44',
 'speed': '2.127秒',
 'style': 'HTTPS'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西桂林',
 'alive_time': '655天',
 'ip': '121.31.193.203',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '3.247秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '3分钟',
 'ip': '110.72.23.44',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '0.987秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '2分钟',
 'ip': '182.88.129.91',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '0.276秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '447天',
 'ip': '121.31.101.86',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '2.447秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '743天',
 'ip': '182.88.179.98',
 'port': '8123',
 'proof_time': '17-11-26 15:33',
 'speed': '3.439秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '河南新乡',
 'alive_time': '1分钟',
 'ip': '123.55.89.195',
 'port': '37330',
 'proof_time': '17-11-26 15:33',
 'speed': '0.24秒',
 'style': 'HTTPS'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '266天',
 'ip': '182.90.48.24',
 'port': '8123',
 'proof_time': '17-11-26 15:31',
 'speed': '4.723秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '519天',
 'ip': '121.31.101.38',
 'port': '8123',
 'proof_time': '17-11-26 15:31',
 'speed': '5.339秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '2小时',
 'ip': '223.241.119.15',
 'port': '8010',
 'proof_time': '17-11-26 15:31',
 'speed': '5.847秒',
 'style': 'HTTPS'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:07 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '1分钟',
 'ip': '110.73.4.88',
 'port': '8123',
 'proof_time': '17-11-26 15:30',
 'speed': '7.944秒',
 'style': 'HTTP'}
2017-11-27 10:38:07 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '1分钟',
 'ip': '223.241.79.127',
 'port': '8010',
 'proof_time': '17-11-26 15:22',
 'speed': '4.026秒',
 'style': 'HTTPS'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.117.49',
 'port': '8010',
 'proof_time': '17-11-26 15:22',
 'speed': '3.079秒',
 'style': 'HTTPS'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.31.210',
 'port': '8123',
 'proof_time': '17-11-26 15:22',
 'speed': '0.857秒',
 'style': 'HTTPS'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '福建泉州',
 'alive_time': '1分钟',
 'ip': '120.37.164.86',
 'port': '37783',
 'proof_time': '17-11-26 15:15',
 'speed': '0.183秒',
 'style': 'HTTP'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '5天',
 'ip': '223.241.79.160',
 'port': '8010',
 'proof_time': '17-11-26 15:00',
 'speed': '5.107秒',
 'style': 'HTTPS'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.116.241',
 'port': '8010',
 'proof_time': '17-11-26 14:46',
 'speed': '5.248秒',
 'style': 'HTTPS'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '7天',
 'ip': '223.241.119.127',
 'port': '8010',
 'proof_time': '17-11-26 14:44',
 'speed': '2.111秒',
 'style': 'HTTP'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西北海',
 'alive_time': '691天',
 'ip': '121.31.197.24',
 'port': '8123',
 'proof_time': '17-11-26 14:33',
 'speed': '6.529秒',
 'style': 'HTTP'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:08 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.33.204',
 'port': '8123',
 'proof_time': '17-11-26 14:22',
 'speed': '3.096秒',
 'style': 'HTTPS'}
2017-11-27 10:38:08 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽芜湖',
 'alive_time': '14天',
 'ip': '223.241.78.206',
 'port': '8010',
 'proof_time': '17-11-26 14:22',
 'speed': '6.24秒',
 'style': 'HTTPS'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '7小时',
 'ip': '112.114.99.50',
 'port': '8118',
 'proof_time': '17-11-26 14:16',
 'speed': '0.329秒',
 'style': 'HTTP'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '10天',
 'ip': '223.241.117.85',
 'port': '8010',
 'proof_time': '17-11-26 14:15',
 'speed': '6.304秒',
 'style': 'HTTPS'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '1分钟',
 'ip': '121.31.81.102',
 'port': '8123',
 'proof_time': '17-11-26 14:15',
 'speed': '0.423秒',
 'style': 'HTTP'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '四川德阳',
 'alive_time': '1分钟',
 'ip': '110.189.207.39',
 'port': '48622',
 'proof_time': '17-11-26 14:15',
 'speed': '0.728秒',
 'style': 'HTTP'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西',
 'alive_time': '102天',
 'ip': '171.108.205.85',
 'port': '53281',
 'proof_time': '17-11-26 14:15',
 'speed': '0.55秒',
 'style': 'HTTPS'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '688天',
 'ip': '110.73.35.51',
 'port': '8123',
 'proof_time': '17-11-26 14:11',
 'speed': '1.264秒',
 'style': 'HTTP'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:09 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西贵港',
 'alive_time': '1分钟',
 'ip': '110.72.45.159',
 'port': '8123',
 'proof_time': '17-11-26 14:00',
 'speed': '3.583秒',
 'style': 'HTTP'}
2017-11-27 10:38:09 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '福建厦门',
 'alive_time': '2天',
 'ip': '120.32.208.19',
 'port': '8118',
 'proof_time': '17-11-26 14:00',
 'speed': '0.172秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '辽宁',
 'alive_time': '1分钟',
 'ip': '42.55.200.32',
 'port': '38406',
 'proof_time': '17-11-26 13:55',
 'speed': '0.305秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏徐州',
 'alive_time': '1分钟',
 'ip': '49.81.10.118',
 'port': '46290',
 'proof_time': '17-11-26 13:55',
 'speed': '0.644秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏',
 'alive_time': '1分钟',
 'ip': '121.226.163.85',
 'port': '32181',
 'proof_time': '17-11-26 13:55',
 'speed': '0.164秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江温州',
 'alive_time': '6分钟',
 'ip': '218.73.134.89',
 'port': '49015',
 'proof_time': '17-11-26 13:50',
 'speed': '1.184秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江舟山',
 'alive_time': '1分钟',
 'ip': '115.209.179.186',
 'port': '37433',
 'proof_time': '17-11-26 13:46',
 'speed': '1.832秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江宁波',
 'alive_time': '27天',
 'ip': '115.217.253.77',
 'port': '30580',
 'proof_time': '17-11-26 13:46',
 'speed': '2.145秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:10 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江宁波',
 'alive_time': '1分钟',
 'ip': '115.217.254.132',
 'port': '33222',
 'proof_time': '17-11-26 13:46',
 'speed': '0.199秒',
 'style': 'HTTPS'}
2017-11-27 10:38:10 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '浙江丽水',
 'alive_time': '1分钟',
 'ip': '115.226.151.41',
 'port': '22042',
 'proof_time': '17-11-26 13:46',
 'speed': '2.174秒',
 'style': 'HTTPS'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '634天',
 'ip': '110.73.1.23',
 'port': '8123',
 'proof_time': '17-11-26 13:33',
 'speed': '4.967秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '河南开封',
 'alive_time': '19小时',
 'ip': '123.163.137.56',
 'port': '808',
 'proof_time': '17-11-26 13:18',
 'speed': '0.119秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '121.231.144.19',
 'port': '6666',
 'proof_time': '17-11-26 13:16',
 'speed': '0.132秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西梧州',
 'alive_time': '328天',
 'ip': '121.31.79.116',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '5.141秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '583天',
 'ip': '110.73.8.229',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '3.229秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '1分钟',
 'ip': '223.241.119.101',
 'port': '8010',
 'proof_time': '17-11-26 13:15',
 'speed': '4.57秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西南宁',
 'alive_time': '1分钟',
 'ip': '115.46.76.45',
 'port': '8123',
 'proof_time': '17-11-26 13:15',
 'speed': '1.934秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '327天',
 'ip': '110.73.7.140',
 'port': '8123',
 'proof_time': '17-11-26 13:11',
 'speed': '6.031秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广西防城港',
 'alive_time': '648天',
 'ip': '110.73.4.128',
 'port': '8123',
 'proof_time': '17-11-26 13:11',
 'speed': '6.114秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '云南临沧',
 'alive_time': '17小时',
 'ip': '112.114.93.56',
 'port': '8118',
 'proof_time': '17-11-26 13:09',
 'speed': '0.418秒',
 'style': 'HTTPS'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '安徽',
 'alive_time': '6天',
 'ip': '223.241.119.13',
 'port': '8010',
 'proof_time': '17-11-26 13:00',
 'speed': '2.216秒',
 'style': 'HTTPS'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '江苏常州',
 'alive_time': '1分钟',
 'ip': '121.231.150.223',
 'port': '6666',
 'proof_time': '17-11-26 13:00',
 'speed': '0.149秒',
 'style': 'HTTPS'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东佛山',
 'alive_time': '1分钟',
 'ip': '119.127.17.162',
 'port': '808',
 'proof_time': '17-11-26 13:00',
 'speed': '3.658秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东佛山',
 'alive_time': '1分钟',
 'ip': '119.127.17.162',
 'port': '808',
 'proof_time': '17-11-26 13:00',
 'speed': '3.264秒',
 'style': 'HTTPS'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.scraper] DEBUG: Scraped from <200 http://www.xicidaili.com/nn/3>
{'addrs': '广东深圳',
 'alive_time': '4小时',
 'ip': '116.30.233.134',
 'port': '8118',
 'proof_time': '17-11-26 12:51',
 'speed': '0.255秒',
 'style': 'HTTP'}
2017-11-27 10:38:11 [scrapy.spidermiddlewares.depth] DEBUG: Ignoring link (depth > 2): http://www.xicidaili.com/nn/4 
2017-11-27 10:38:11 [scrapy.core.engine] INFO: Closing spider (finished)
2017-11-27 10:38:11 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 1372,
 'downloader/request_count': 3,
 'downloader/request_method_count/GET': 3,
 'downloader/response_bytes': 25046,
 'downloader/response_count': 3,
 'downloader/response_status_count/200': 3,
 'dupefilter/filtered': 200,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2017, 11, 27, 2, 38, 11, 933475),
 'item_scraped_count': 300,
 'log_count/DEBUG': 406,
 'log_count/INFO': 7,
 'log_count/WARNING': 1,
 'request_depth_max': 2,
 'response_received_count': 3,
 'scheduler/dequeued': 3,
 'scheduler/dequeued/memory': 3,
 'scheduler/enqueued': 3,
 'scheduler/enqueued/memory': 3,
 'start_time': datetime.datetime(2017, 11, 27, 2, 37, 34, 70640)}
2017-11-27 10:38:11 [scrapy.core.engine] INFO: Spider closed (finished)
